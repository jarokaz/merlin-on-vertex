{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7086876-72ed-4ac8-aeba-f05dbc641798",
   "metadata": {},
   "source": [
    "# Serving Recommender Models for Online Prediction using NVIDIA Triton and Vertex AI\n",
    "\n",
    "This notebooks demonstrates serving a HugeCTR model using Triton server on Vertex AI prediction.\n",
    "The notebook compiles prescriptive guidance for the following tasks:\n",
    "\n",
    "1. Exporting the Triton ensemble model consisting of NVTabular preprocessing workflow HugeCTR model.\n",
    "2. Uploading the model and its metadata to Vertex Models.\n",
    "3. Building a custom container derived from NVIDIA NGC Merlin inference image.\n",
    "4. Deploy the model to Vertex AI Prediction.\n",
    "5. Getting the inference on a sample data points using the endpoint.\n",
    "\n",
    "## Triton Inference Server Overview\n",
    "\n",
    "[Triton Inference Server](https://github.com/triton-inference-server/server) provides an inferencing solution optimized for both CPUs and GPUs. Triton can run multiple models from the same or different frameworks concurrently on a single GPU or CPU. In a multi-GPU server, it automatically creates an instance of each model on each GPU to increase utilization without extra coding.It supports real-time inferencing, batch inferencing to maximize GPU/CPU utilization, and streaming inference with built-in support for audio streaming input. It also supports model ensemble for use cases that require multiple models to perform end-to-end inference.\n",
    "\n",
    "At a high-level, the Triton Inference Server high-level architecture works as follows:\n",
    "- The model repository is a file-system based repository of the models that Triton will make available for inferencing. \n",
    "- Inference requests arrive at the server via either HTTP/REST or gRPC or then routed to the appropriate per-model scheduler. \n",
    "- Triton implements multiple scheduling and batching algorithms that can be configured on a model-by-model basis.\n",
    "- The backend performs inferencing using the inputs provided in the batched requests to produce the requested outputs.\n",
    "\n",
    "Triton server provides readiness and liveness health endpoints, as well as utilization, throughput, and latency metrics, which enables the integration of Triton into deployment environment, such as Vertex AI Prediction.\n",
    "\n",
    "In this example, we use Triton to serve an ensemble model that contains data processing workflow and HugeCTR model trained on Criteo data. The model is deployed into Vertex AI Prediction. This is shown in the following figure:\n",
    "\n",
    "<img src=\"./images/triton-vertex.png\" alt=\"Triton Architecture\" style=\"width:70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b3137-249c-49a3-a8be-f459b3774ea2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this section of the notebook you configure your environment settings, including a GCP project, a GCS compute region, and a GCP Bucket. \n",
    "You also set the locations of the saved NVTaubular workflow, created in [01-dataset-preprocessing.ipynb](01-dataset-preprocessing.ipynb) and the trained HugeCTR model, created in [02-model-training-hugectr.ipynb](02-model-training-hugectr.ipynb) notebook.\n",
    "\n",
    "Make sure to update the below cells with the values reflecting your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb89d6b2-b684-413c-b98e-64a868a84b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9791d621-22e8-41bc-8681-a48aec45ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from src.serving import export\n",
    "from src.configs import EnsembleConfig\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e20da19-0dda-4a58-b606-341e50c9bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev' # Change to your project.\n",
    "REGION = 'us-central1'  # Change to your region.\n",
    "STAGING_BUCKET = 'jk-merlin-dev' # Change to your bucket.\n",
    "MODEL_REPOSITORY_BUCKET = 'jk-vertex-staging'\n",
    "LOCAL_WORKSPACE = '/home/jupyter/staging'\n",
    "\n",
    "MODEL_NAME = 'deepfm'\n",
    "MODEL_VERSION = 'v01'\n",
    "MODEL_DISPLAY_NAME = f'hugectr-{MODEL_NAME}-{MODEL_VERSION}'\n",
    "MODEL_DESCRIPTION = 'HugeCTR DeepFM model'\n",
    "ENDPOINT_DISPLAY_NAME = f'hugectr-{MODEL_NAME}-{MODEL_VERSION}'\n",
    "\n",
    "EXPORTED_MODELS_DIR = f'gs://{MODEL_REPOSITORY_BUCKET}/hugectr_models'\n",
    "\n",
    "IMAGE_NAME = 'triton-deploy-hugectr'\n",
    "IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{IMAGE_NAME}\"\n",
    "DOCKERFILE = 'src/Dockerfile.triton'\n",
    "\n",
    "WORKFLOW_MODEL_DIR = \"gs://criteo-datasets/criteo_processed_parquet/workflow\" # Change to GCS path of the nvt workflow.\n",
    "HUGECTR_MODEL_DIR = \"gs://merlin-models/hugectr_deepfm_21.09\" # Change to GCS path of the hugectr trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e3f45-2bab-48fb-9b81-4e0e65635ece",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e0cca3-11e6-4454-af41-c5c632dbbeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9c710-537a-49c9-86d5-fae7e9f2b4be",
   "metadata": {},
   "source": [
    "## 1. Exporting Triton ensemble model\n",
    "\n",
    "The Triton ensemble model consists of NVTabular preprocessing workflow HugeCTR model\n",
    "\n",
    "### Copy a hugectr saved model and a fitted NVTabular workflow to a local staging folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4fc36f-621e-4471-97ac-0580d2bca48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C1.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C10.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C11.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C12.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C13.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C14.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C15.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C16.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C17.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C18.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C19.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C2.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C21.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C20.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C22.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C23.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C24.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C25.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C26.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C3.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C4.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C5.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C7.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C6.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C8.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/workflow.pkl...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/categories/unique.C9.parquet...\n",
      "Copying gs://criteo-datasets/criteo_processed_parquet/workflow/metadata.json... \n",
      "\\ [28/28 files][289.7 MiB/289.7 MiB] 100% Done                                  \n",
      "Operation completed over 28 objects/289.7 MiB.                                   \n",
      "Copying gs://merlin-models/hugectr_deepfm_21.09/deepfm.json...\n",
      "Copying gs://merlin-models/hugectr_deepfm_21.09/deepfm0_opt_sparse_0.model...   \n",
      "Copying gs://merlin-models/hugectr_deepfm_21.09/deepfm0_sparse_0.model/emb_vector...\n",
      "Copying gs://merlin-models/hugectr_deepfm_21.09/deepfm0_sparse_0.model/key...   \n",
      "Copying gs://merlin-models/hugectr_deepfm_21.09/deepfm0_sparse_0.model/slot_id...\n",
      "Copying gs://merlin-models/hugectr_deepfm_21.09/deepfm_dense_0.model...         \n",
      "Copying gs://merlin-models/hugectr_deepfm_21.09/deepfm_opt_dense_0.model...     \n",
      "| [7/7 files][  4.2 GiB/  4.2 GiB] 100% Done  69.9 MiB/s ETA 00:00:00           \n",
      "Operation completed over 7 objects/4.2 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(LOCAL_WORKSPACE):\n",
    "    shutil.rmtree(LOCAL_WORKSPACE)\n",
    "os.makedirs(LOCAL_WORKSPACE)\n",
    "\n",
    "!gsutil -m cp -r {WORKFLOW_MODEL_DIR} {LOCAL_WORKSPACE}\n",
    "!gsutil -m cp -r {HUGECTR_MODEL_DIR} {LOCAL_WORKSPACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45757f1d-2e9b-4035-b982-d4c289e67dec",
   "metadata": {},
   "source": [
    "### Export the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76abc820-3603-4b8b-9dec-a22c07d31d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_config = EnsembleConfig()\n",
    "local_workflow_path = Path(LOCAL_WORKSPACE) / Path(WORKFLOW_MODEL_DIR).parts[-1]\n",
    "local_saved_model_path = Path(LOCAL_WORKSPACE) / Path(HUGECTR_MODEL_DIR).parts[-1]\n",
    "local_ensemble_path = Path(LOCAL_WORKSPACE) / f'triton-ensemble-{time.strftime(\"%Y%m%d%H%M%S\")}'\n",
    "container_model_registry_path = '/models'\n",
    "\n",
    "export.export_ensemble(\n",
    "    model_name=MODEL_NAME,\n",
    "    workflow_path=local_workflow_path,\n",
    "    saved_model_path=local_saved_model_path,\n",
    "    output_path=local_ensemble_path,\n",
    "    categorical_columns=ensemble_config.categorical_columns,\n",
    "    continuous_columns=ensemble_config.continuous_columns,\n",
    "    label_columns=ensemble_config.label_columns,\n",
    "    num_slots=ensemble_config.num_slots,\n",
    "    max_nnz=ensemble_config.max_nnz,\n",
    "    num_outputs=ensemble_config.num_outputs,\n",
    "    embedding_vector_size=ensemble_config.embedding_vector_size,\n",
    "    max_batch_size=ensemble_config.max_batch_size,\n",
    "    model_registry_path=container_model_registry_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d654b85e-db4a-47c2-97d2-960bc802fef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "drwxr-xr-x 5 jupyter jupyter 4096 Oct 30 01:55 .\n",
      "drwxr-xr-x 5 jupyter jupyter 4096 Oct 30 01:55 ..\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 Oct 30 01:55 deepfm\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 Oct 30 01:55 deepfm_ens\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 Oct 30 01:55 deepfm_nvt\n",
      "-rw-r--r-- 1 jupyter jupyter  222 Oct 30 01:55 ps.json\n"
     ]
    }
   ],
   "source": [
    "! ls -la {local_ensemble_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481fdc6e-1047-44a0-b6fa-2bd7c5b6e232",
   "metadata": {},
   "source": [
    "### Upload the ensemble to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad435708-b92b-40d6-83f9-3b685bfeaba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm/config.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm/1/deepfm0_opt_sparse_0.model [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm/1/deepfm.json [Content-Type=application/json]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm/1/deepfm_opt_dense_0.model [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm/1/deepfm_dense_0.model [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm/1/deepfm0_sparse_0.model/emb_vector [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm/1/deepfm0_sparse_0.model/slot_id [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm/1/deepfm0_sparse_0.model/key [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_ens/config.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/model.py [Content-Type=text/x-python]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/config.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/metadata.json [Content-Type=application/json]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/workflow.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/column_types.json [Content-Type=application/json]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C9.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C23.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C25.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C16.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C13.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C4.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C21.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C17.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C3.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C15.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C24.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C10.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C22.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C8.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C14.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C1.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C19.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C7.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C2.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/ps.json [Content-Type=application/json]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C5.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C26.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C12.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C18.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C6.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C20.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/staging/triton-ensemble-20211030015518/deepfm_nvt/1/workflow/categories/unique.C11.parquet [Content-Type=application/octet-stream]...\n",
      "/ [41/41 files][  4.5 GiB/  4.5 GiB] 100% Done 105.6 MiB/s ETA 00:00:00         \n",
      "Operation completed over 41 objects/4.5 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "gcs_ensemble_path = '{}/{}'.format(EXPORTED_MODELS_DIR, Path(local_ensemble_path).parts[-1])\n",
    "\n",
    "!gsutil -m cp -r {local_ensemble_path}/* {gcs_ensemble_path}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f662a18-0b51-4b30-8e3f-81daf64ca5a9",
   "metadata": {},
   "source": [
    "## 2. Building a custom container derived from NVIDIA NGC Merlin inference image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fff22-3541-466a-9d2c-8e007cfb4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp src/Dockerfile.triton src/Dockerfile\n",
    "! gcloud builds submit --timeout \"2h\" --tag {IMAGE_URI} src --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f7ae3-76c4-4bfe-8a80-44d3567b0b6d",
   "metadata": {},
   "source": [
    "## 3. Uploading the model and its metadata to Vertex Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e3c2ac-90fb-4175-b185-d2981cbdebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/895222332033/locations/us-central1/models/8950064232515239936/operations/1915373857158463488\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/895222332033/locations/us-central1/models/8950064232515239936\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/895222332033/locations/us-central1/models/8950064232515239936')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projects/895222332033/locations/us-central1/models/8950064232515239936'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_route = \"/v2/health/ready\"\n",
    "predict_route = f\"/v2/models/{MODEL_NAME}_ens/infer\"\n",
    "serving_container_ports = [8000]\n",
    "in_container_model_repository = '/models'\n",
    "serving_container_args = [in_container_model_repository]\n",
    "\n",
    "\n",
    "model = vertex_ai.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    description=MODEL_DESCRIPTION,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    "    artifact_uri=gcs_ensemble_path,\n",
    "    serving_container_args=serving_container_args,\n",
    "    sync=True\n",
    ")\n",
    "\n",
    "model.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c572a7c-c5e5-4383-bbd5-ce11b6659945",
   "metadata": {},
   "source": [
    "## 4. Deploying the model to Vertex AI Prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763abf60-c325-4222-b550-0aca98492d15",
   "metadata": {},
   "source": [
    "### Create the Vertex Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ef58a0-1f13-40a7-b545-f6a75ee0fcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/895222332033/locations/us-central1/endpoints/6144326062709932032/operations/1805598616241307648\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/895222332033/locations/us-central1/endpoints/6144326062709932032\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/895222332033/locations/us-central1/endpoints/6144326062709932032')\n"
     ]
    }
   ],
   "source": [
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=ENDPOINT_DISPLAY_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866fd6fc-2777-457e-b446-8b1532984746",
   "metadata": {},
   "source": [
    "### Deploy the model to Vertex Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf2bb85f-330c-4ce6-9a8f-d5b96772ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-8\"\n",
    "accelerator_type=\"NVIDIA_TESLA_T4\"\n",
    "accelerator_count = 1\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fd27dda-7c1b-4ce5-9477-e62a9f1199bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/895222332033/locations/us-central1/endpoints/6144326062709932032\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/895222332033/locations/us-central1/endpoints/6144326062709932032/operations/1566907835990671360\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/895222332033/locations/us-central1/endpoints/6144326062709932032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f5fba5a1730> \n",
       "resource name: projects/895222332033/locations/us-central1/endpoints/6144326062709932032"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "    machine_type=machine_type,\n",
    "    min_replica_count=min_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c71d4-56c4-4f24-aee6-d1b96f6e4e8a",
   "metadata": {},
   "source": [
    "## 5. Invoking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924669cf-5442-4454-b881-e2a792a96f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'id': '1',\n",
    "    'inputs': [\n",
    "        {'name': 'I1','shape': [3, 1], 'datatype': 'INT32', 'data': [5, 32, 0]},\n",
    "        {'name': 'I2', 'shape': [3, 1], 'datatype': 'INT32', 'data': [110, 3, 233]},\n",
    "        {'name': 'I3', 'shape': [3, 1], 'datatype': 'INT32', 'data': [0, 5, 1]},\n",
    "        {'name': 'I4', 'shape': [3, 1], 'datatype': 'INT32', 'data': [16, 0, 146]},\n",
    "        {'name': 'I5', 'shape': [3, 1], 'datatype': 'INT32', 'data': [0, 1, 1]},\n",
    "        {'name': 'I6', 'shape': [3, 1], 'datatype': 'INT32', 'data': [1, 0, 0]},\n",
    "        {'name': 'I7', 'shape': [3, 1], 'datatype': 'INT32', 'data': [0, 0, 0]},\n",
    "        {'name': 'I8', 'shape': [3, 1], 'datatype': 'INT32', 'data': [14, 61, 99]},\n",
    "        {'name': 'I9', 'shape': [3, 1], 'datatype': 'INT32', 'data': [7, 5, 7]},\n",
    "        {'name': 'I10', 'shape': [3, 1], 'datatype': 'INT32', 'data': [1, 0, 0]},\n",
    "        {'name': 'I11', 'shape': [3, 1], 'datatype': 'INT32', 'data': [0, 1, 1]},\n",
    "        {'name': 'I12', 'shape': [3, 1], 'datatype': 'INT32', 'data': [306, 3157, 3101]},\n",
    "        {'name': 'I13', 'shape': [3, 1], 'datatype': 'INT32', 'data': [0, 5, 1]},\n",
    "        {'name': 'C1', 'shape': [3, 1], 'datatype': 'INT32', 'data': [1651969401, -436994675, 1651969401]},\n",
    "        {'name': 'C2', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-501260968, -1599406170, -1382530557]},\n",
    "        {'name': 'C3', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-1343601617, 1873417685, 1656669709]},\n",
    "        {'name': 'C4', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-1805877297, -628476895, 946620910]},\n",
    "        {'name': 'C5', 'shape': [3, 1], 'datatype': 'INT32', 'data': [951068488, 1020698403, -413858227]},\n",
    "        {'name': 'C6', 'shape': [3, 1], 'datatype': 'INT32', 'data': [1875733963, 1875733963, 1875733963]},\n",
    "        {'name': 'C7', 'shape': [3, 1], 'datatype': 'INT32', 'data': [897624609, -1424560767, -1242174622]},\n",
    "        {'name': 'C8', 'shape': [3, 1], 'datatype': 'INT32', 'data': [679512323, 1128426537, -772617077]},\n",
    "        {'name': 'C9', 'shape': [3, 1], 'datatype': 'INT32', 'data': [1189011366, 502653268, 776897055]},\n",
    "        {'name': 'C10', 'shape': [3, 1], 'datatype': 'INT32', 'data': [771915201, 2112471209, 771915201]},\n",
    "        {'name': 'C11', 'shape': [3, 1], 'datatype': 'INT32', 'data': [209470001, 1716706404, 209470001]},\n",
    "        {'name': 'C12', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-1785193185, -1712632281, 309420420]},\n",
    "        {'name': 'C13', 'shape': [3, 1], 'datatype': 'INT32', 'data': [12976055, 12976055, 12976055]},\n",
    "        {'name': 'C14', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-1102125769, -1102125769, -1102125769]},\n",
    "        {'name': 'C15', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-1978960692, -205783399, -150008565]},\n",
    "        {'name': 'C16', 'shape': [3, 1], 'datatype': 'INT32', 'data': [1289502458, 1289502458, 1289502458]},\n",
    "        {'name': 'C17', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-771205462, -771205462, -771205462]},\n",
    "        {'name': 'C18', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-1206449222, -1578429167, 1653545869]},\n",
    "        {'name': 'C19', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-1793932789, -1793932789, -1793932789]},\n",
    "        {'name': 'C20', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-1014091992, -20981661, -1014091992]},\n",
    "        {'name': 'C21', 'shape': [3, 1], 'datatype': 'INT32', 'data': [351689309, -1556988767, 351689309]},\n",
    "        {'name': 'C22', 'shape': [3, 1], 'datatype': 'INT32', 'data': [632402057, -924717482, 632402057]},\n",
    "        {'name': 'C23', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-675152885, 391309800, -675152885]},\n",
    "        {'name': 'C24', 'shape': [3, 1], 'datatype': 'INT32', 'data': [2091868316, 1966410890, 883538181]},\n",
    "        {'name': 'C25', 'shape': [3, 1], 'datatype': 'INT32', 'data': [809724924, -1726799382, -10139646]},\n",
    "        {'name': 'C26', 'shape': [3, 1], 'datatype': 'INT32', 'data': [-317696227, -1218975401, -317696227]}]\n",
    "}\n",
    "\n",
    "with open('criteo_payload.json', 'w') as f:\n",
    "    json.dump(payload, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f98d37f-87bf-47d8-951e-a88dee48421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"1\",\"model_name\":\"deepfm_ens\",\"model_version\":\"1\",\"parameters\":{\"sequence_id\":0,\"sequence_start\":false,\"sequence_end\":false},\"outputs\":[{\"name\":\"OUTPUT0\",\"datatype\":\"FP32\",\"shape\":[3],\"data\":[0.07325490564107895,0.04518262296915054,0.04656011983752251]}]}"
     ]
    }
   ],
   "source": [
    "uri = f'https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{endpoint.name}:rawPredict'\n",
    "\n",
    "! curl -X POST \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\"  \\\n",
    "{uri} \\\n",
    "-d @criteo_payload.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf2954-7807-4282-8143-ba4c314bf632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m82",
   "type": "gcloud",
   "uri": "gcr.io/jk-mlops-dev/merlin-dev:latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
