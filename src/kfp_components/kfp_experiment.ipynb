{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Standard\n",
    "import json\n",
    "\n",
    "# Google Cloud\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Kubeflow Pipelines\n",
    "import kfp\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import (\n",
    "    Categorify,\n",
    "    Clip,\n",
    "    FillMissing,\n",
    "    Normalize,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Pipeline: Source data in GCS\n",
    "## Data Definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import components and pipeline definition\n",
    "from pipeline_gcs import preprocessing_pipeline_gcs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Columns and dtypes definition\n",
    "cont_names = [\"I\" + str(x) for x in range(1, 14)]\n",
    "cat_names = [\"C\" + str(x) for x in range(1, 27)]\n",
    "columns = [\"label\"] + cont_names + cat_names\n",
    "\n",
    "# Specify column dtypes. Note that \"hex\" means that\n",
    "# the values will be hexadecimal strings that should\n",
    "# be converted to int32\n",
    "cols_dtype = {}\n",
    "cols_dtype[\"label\"] = 'int32'\n",
    "for x in cont_names:\n",
    "    cols_dtype[x] = 'int32'\n",
    "for x in cat_names:\n",
    "    cols_dtype[x] = 'hex'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Transformation pipeline\n",
    "num_buckets = 10000000\n",
    "categorify_op = Categorify(max_size=num_buckets)\n",
    "cat_features = cat_names >> categorify_op\n",
    "cont_features = cont_names >> FillMissing() >> Clip(min_value=0) >> Normalize()\n",
    "features = cat_features + cont_features + ['label']\n",
    "\n",
    "# Create and save workflow\n",
    "workflow = nvt.Workflow(features)\n",
    "# workflow.save(local_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_paths = ['renatoleite-criteo-partial/flat_data/day_0']\n",
    "valid_paths = ['renatoleite-criteo-partial/flat_data/day_1']\n",
    "output_path = 'renatoleite-criteo-partial/converted'\n",
    "workflow_path = 'renatoleite-criteo-partial/saved_workflow'\n",
    "output_transformed = 'renatoleite-criteo-partial/transformed_data'\n",
    "\n",
    "sep = '\\t'\n",
    "gpus = '0'\n",
    "\n",
    "recursive = False\n",
    "shuffle = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "parameter_values = {\n",
    "    'train_paths': json.dumps(train_paths),\n",
    "    'valid_paths': json.dumps(valid_paths),\n",
    "    'output_path': output_path,\n",
    "    'columns': json.dumps(columns),\n",
    "    'cols_dtype': json.dumps(cols_dtype),\n",
    "    'output_transformed': output_transformed,\n",
    "    'workflow_path': workflow_path,\n",
    "    'sep': sep,\n",
    "    'gpus': gpus,\n",
    "    'recursive': json.dumps(recursive),\n",
    "    'shuffle': json.dumps(shuffle)\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Compile Pipeline\n",
    "PACKAGE_PATH = 'pipeline_gcs.json'\n",
    "compiler.Compiler().compile(\n",
    "       pipeline_func=preprocessing_pipeline_gcs,\n",
    "       package_path=PACKAGE_PATH\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "project_id = 'renatoleite-mldemos'\n",
    "region = 'us-central1'\n",
    "staging_bucket = 'gs://renatoleite-staging'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "aiplatform.init(\n",
    "    project=project_id,\n",
    "    location=region,\n",
    "    staging_bucket=staging_bucket\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name='nvt_convert_pipeline_gcs',\n",
    "    template_path=PACKAGE_PATH,\n",
    "    enable_caching=False,\n",
    "    parameter_values=parameter_values,\n",
    ")\n",
    "\n",
    "pipeline_job.run()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) Pipeline: Source data in BQ"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Import components and pipeline definition\n",
    "from pipeline_bq import preprocessing_pipeline_bq"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "output_path = 'renatoleite-criteo-partial/bq_converted'\n",
    "bq_project = 'renatoleite-mldemos'\n",
    "bq_dataset_id = 'criteo_pipeline'\n",
    "bq_table_train = 'train'\n",
    "bq_table_valid = 'valid'\n",
    "location = 'US'\n",
    "\n",
    "workflow_path = 'renatoleite-criteo-partial/saved_workflow'\n",
    "output_transformed = 'renatoleite-criteo-partial/bq_transformed_data'\n",
    "gpus = '0'\n",
    "\n",
    "recursive = False\n",
    "shuffle = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "parameter_values = {\n",
    "    'bq_table_train': bq_table_train,\n",
    "    'bq_table_valid': bq_table_valid,\n",
    "    'output_path': output_path,\n",
    "    'bq_project': bq_project,\n",
    "    'bq_dataset_id': bq_dataset_id,\n",
    "    'location': location,\n",
    "    'gpus': gpus,\n",
    "    'workflow_path': workflow_path,\n",
    "    'output_transformed': output_transformed,\n",
    "    'recursive': recursive,\n",
    "    'shuffle': json.dumps(shuffle)\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Compile Pipeline\n",
    "PACKAGE_PATH = 'pipeline_bq.json'\n",
    "compiler.Compiler().compile(\n",
    "       pipeline_func=preprocessing_pipeline_bq,\n",
    "       package_path=PACKAGE_PATH\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "project_id = 'renatoleite-mldemos'\n",
    "region = 'us-central1'\n",
    "staging_bucket = 'gs://renatoleite-staging'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "aiplatform.init(\n",
    "    project=project_id,\n",
    "    location=region,\n",
    "    staging_bucket=staging_bucket\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name='nvt_convert_pipeline_bq',\n",
    "    template_path=PACKAGE_PATH,\n",
    "    enable_caching=False,\n",
    "    parameter_values=parameter_values,\n",
    ")\n",
    "\n",
    "pipeline_job.run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Pipeline: Source GCS and output to Feature Store"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 1) Create op to export from gcs parquet back to BQ\n",
    "# 2) Export dataset to Feature Store"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}