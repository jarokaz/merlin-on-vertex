Starting Triton Server
I1029 18:09:18.315204 2271 metrics.cc:298] Collecting metrics for GPU 0: A100-SXM4-40GB
I1029 18:09:18.315434 2271 metrics.cc:298] Collecting metrics for GPU 1: A100-SXM4-40GB
I1029 18:09:18.557113 2271 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f8112000000' with size 268435456
I1029 18:09:18.558141 2271 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I1029 18:09:18.558158 2271 cuda_memory_manager.cc:105] CUDA memory pool is created on device 1 with size 67108864
I1029 18:09:18.703599 2271 model_repository_manager.cc:1022] loading: deepfm:1
I1029 18:09:18.803994 2271 model_repository_manager.cc:1022] loading: deepfm_nvt:1
I1029 18:09:18.834040 2271 hugectr.cc:1037] TRITONBACKEND_Initialize: hugectr
I1029 18:09:18.834078 2271 hugectr.cc:1047] Triton TRITONBACKEND API version: 1.6
I1029 18:09:18.834084 2271 hugectr.cc:1053] 'hugectr' TRITONBACKEND API version: 1.6
I1029 18:09:18.834097 2271 hugectr.cc:1078] The HugeCTR backend Repository location: /opt/tritonserver/backends/hugectr
I1029 18:09:18.834132 2271 hugectr.cc:1088] The HugeCTR backend configuration:
{"cmdline":{"ps":"/models/ps.json"}}
I1029 18:09:18.834243 2271 hugectr.cc:280] *****Parsing Parameter Server Configuration from /models/ps.json
I1029 18:09:18.834283 2271 hugectr.cc:294] Enable support for Int64 embedding key: 1
I1029 18:09:18.834294 2271 hugectr.cc:298] The depolyment Data base type is: local
I1029 18:09:18.834301 2271 hugectr.cc:304] The depolyment cache_size_percentage_redis is: 
I1029 18:09:18.834307 2271 hugectr.cc:308] Redis ip is: 127.0.0.1:7000
I1029 18:09:18.834313 2271 hugectr.cc:312] Local RocksDB path is: 
I1029 18:09:18.834321 2271 hugectr.cc:323] The model name is: deepfm
I1029 18:09:18.834327 2271 hugectr.cc:326] The model dense file path is: /models/deepfm/1/deepfm_dense_0.model
I1029 18:09:18.834335 2271 hugectr.cc:331] The model network file path is: /models/deepfm/1/deepfm.json
I1029 18:09:18.834346 2271 hugectr.cc:364] *****The HugeCTR Backend Parameter Server is creating...*****
I1029 18:09:18.834359 2271 hugectr.cc:372] ***** Parameter Server(Int64) is creating...***** 
[29d18h09m18s][HUGECTR][INFO]: default_emb_vec_value is not specified using default: 0.000000
I1029 18:10:11.390608 2271 hugectr.cc:380] *****The HugeCTR Backend Backend created the Parameter Server successfully!*****
I1029 18:10:11.394831 2271 hugectr.cc:1157] TRITONBACKEND_ModelInitialize: deepfm (version 1)
I1029 18:10:11.394853 2271 hugectr.cc:1172] Repository location: /models/deepfm
I1029 18:10:11.394859 2271 hugectr.cc:1189] backend configuration in mode:
{"cmdline":{"ps":"/models/ps.json"}}
I1029 18:10:11.544854 2271 hugectr.cc:570] Verifying model configuration:
{
    "name": "deepfm",
    "platform": "",
    "backend": "hugectr",
    "version_policy": {
        "latest": {
            "num_versions": 1
        }
    },
    "max_batch_size": 64,
    "input": [
        {
            "name": "DES",
            "data_type": "TYPE_FP32",
            "format": "FORMAT_NONE",
            "dims": [
                -1
            ],
            "is_shape_tensor": false,
            "allow_ragged_batch": false
        },
        {
            "name": "CATCOLUMN",
            "data_type": "TYPE_INT64",
            "format": "FORMAT_NONE",
            "dims": [
                -1
            ],
            "is_shape_tensor": false,
            "allow_ragged_batch": false
        },
        {
            "name": "ROWINDEX",
            "data_type": "TYPE_INT32",
            "format": "FORMAT_NONE",
            "dims": [
                -1
            ],
            "is_shape_tensor": false,
            "allow_ragged_batch": false
        }
    ],
    "output": [
        {
            "name": "OUTPUT0",
            "data_type": "TYPE_FP32",
            "dims": [
                -1
            ],
            "label_filename": "",
            "is_shape_tensor": false
        }
    ],
    "batch_input": [],
    "batch_output": [],
    "optimization": {
        "priority": "PRIORITY_DEFAULT",
        "input_pinned_memory": {
            "enable": true
        },
        "output_pinned_memory": {
            "enable": true
        },
        "gather_kernel_buffer_threshold": 0,
        "eager_batching": false
    },
    "instance_group": [
        {
            "name": "deepfm_0",
            "kind": "KIND_GPU",
            "count": 1,
            "gpus": [
                0
            ],
            "secondary_devices": [],
            "profile": [],
            "passive": false,
            "host_policy": ""
        }
    ],
    "default_model_filename": "",
    "cc_model_filenames": {},
    "metric_tags": {},
    "parameters": {
        "config": {
            "string_value": "/models/deepfm/1/deepfm.json"
        },
        "cat_feature_num": {
            "string_value": "26"
        },
        "label_dim": {
            "string_value": "1"
        },
        "max_nnz": {
            "string_value": "2"
        },
        "embedding_vector_size": {
            "string_value": "11"
        },
        "gpucacheper": {
            "string_value": "0.5"
        },
        "des_feature_num": {
            "string_value": "13"
        },
        "embeddingkey_long_type": {
            "string_value": "true"
        },
        "gpucache": {
            "string_value": "true"
        },
        "slots": {
            "string_value": "26"
        }
    },
    "model_warmup": []
}
I1029 18:10:11.544992 2271 hugectr.cc:656] The model configuration:
{
    "name": "deepfm",
    "platform": "",
    "backend": "hugectr",
    "version_policy": {
        "latest": {
            "num_versions": 1
        }
    },
    "max_batch_size": 64,
    "input": [
        {
            "name": "DES",
            "data_type": "TYPE_FP32",
            "format": "FORMAT_NONE",
            "dims": [
                -1
            ],
            "is_shape_tensor": false,
            "allow_ragged_batch": false
        },
        {
            "name": "CATCOLUMN",
            "data_type": "TYPE_INT64",
            "format": "FORMAT_NONE",
            "dims": [
                -1
            ],
            "is_shape_tensor": false,
            "allow_ragged_batch": false
        },
        {
            "name": "ROWINDEX",
            "data_type": "TYPE_INT32",
            "format": "FORMAT_NONE",
            "dims": [
                -1
            ],
            "is_shape_tensor": false,
            "allow_ragged_batch": false
        }
    ],
    "output": [
        {
            "name": "OUTPUT0",
            "data_type": "TYPE_FP32",
            "dims": [
                -1
            ],
            "label_filename": "",
            "is_shape_tensor": false
        }
    ],
    "batch_input": [],
    "batch_output": [],
    "optimization": {
        "priority": "PRIORITY_DEFAULT",
        "input_pinned_memory": {
            "enable": true
        },
        "output_pinned_memory": {
            "enable": true
        },
        "gather_kernel_buffer_threshold": 0,
        "eager_batching": false
    },
    "instance_group": [
        {
            "name": "deepfm_0",
            "kind": "KIND_GPU",
            "count": 1,
            "gpus": [
                0
            ],
            "secondary_devices": [],
            "profile": [],
            "passive": false,
            "host_policy": ""
        }
    ],
    "default_model_filename": "",
    "cc_model_filenames": {},
    "metric_tags": {},
    "parameters": {
        "config": {
            "string_value": "/models/deepfm/1/deepfm.json"
        },
        "cat_feature_num": {
            "string_value": "26"
        },
        "label_dim": {
            "string_value": "1"
        },
        "max_nnz": {
            "string_value": "2"
        },
        "embedding_vector_size": {
            "string_value": "11"
        },
        "gpucacheper": {
            "string_value": "0.5"
        },
        "des_feature_num": {
            "string_value": "13"
        },
        "embeddingkey_long_type": {
            "string_value": "true"
        },
        "gpucache": {
            "string_value": "true"
        },
        "slots": {
            "string_value": "26"
        }
    },
    "model_warmup": []
}
I1029 18:10:11.545048 2271 hugectr.cc:693] slots set is : 26
I1029 18:10:11.545057 2271 hugectr.cc:701] desene number is : 13
I1029 18:10:11.545071 2271 hugectr.cc:710] cat_feature number is : 26
I1029 18:10:11.545078 2271 hugectr.cc:723] embedding size is  11
I1029 18:10:11.545090 2271 hugectr.cc:731] maxnnz is 2
I1029 18:10:11.545104 2271 hugectr.cc:738] Hugectr model config path is /models/deepfm/1/deepfm.json
I1029 18:10:11.545110 2271 hugectr.cc:748] support gpu cache is 1
I1029 18:10:11.545121 2271 hugectr.cc:768] gpu cache per is 0.500000
I1029 18:10:11.545127 2271 hugectr.cc:785] Label dim is 1
I1029 18:10:11.545132 2271 hugectr.cc:797] Support long long embedding key is 1
I1029 18:10:11.545140 2271 hugectr.cc:802] max_batch_size is 64
I1029 18:10:11.545149 2271 hugectr.cc:813] ******Creating Embedding Cache for model deepfm in device 0
I1029 18:10:11.561885 2271 hugectr.cc:833] ******Creating Embedding Cache for model deepfm successfully
I1029 18:10:11.563742 2271 hugectr.cc:1258] TRITONBACKEND_ModelInstanceInitialize: deepfm_0 (device 0)
I1029 18:10:11.563762 2271 hugectr.cc:948] Triton Model Instance Initialization on device 0
I1029 18:10:11.563776 2271 hugectr.cc:959] Dense Feature buffer allocation: 
I1029 18:10:11.618965 2271 hugectr.cc:965] Categorical Feature buffer allocation: 
I1029 18:10:11.620174 2271 hugectr.cc:980] Categorical Row Index buffer allocation: 
I1029 18:10:11.620209 2271 hugectr.cc:986] Predict result buffer allocation: 
I1029 18:10:11.620247 2271 hugectr.cc:1281] ******Loading HugeCTR Model***** 
I1029 18:10:11.620256 2271 hugectr.cc:1004] The model origin json configuration file path is: /models/deepfm/1/deepfm.json
[29d18h10m11s][HUGECTR][INFO]: Global seed is 928211990
[29d18h10m13s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.
[29d18h10m13s][HUGECTR][INFO]: Start all2all warmup
[29d18h10m13s][HUGECTR][INFO]: End all2all warmup
[29d18h10m13s][HUGECTR][INFO]: Use mixed precision: 0
[29d18h10m13s][HUGECTR][INFO]: start create embedding for inference
[29d18h10m13s][HUGECTR][INFO]: sparse_input name data1
[29d18h10m13s][HUGECTR][INFO]: create embedding for inference success
[29d18h10m13s][HUGECTR][INFO]: Inference stage skip BinaryCrossEntropyLoss layer, replaced by Sigmoid layer
I1029 18:10:13.643871 2271 hugectr.cc:1007] ******Loading HugeCTR model successfully
I1029 18:10:13.644003 2271 python.cc:1875] TRITONBACKEND_ModelInstanceInitialize: deepfm_nvt_0 (CPU device 0)
I1029 18:10:13.644408 2271 model_repository_manager.cc:1183] successfully loaded 'deepfm' version 1
I1029 18:11:23.684754 2271 model_repository_manager.cc:1183] successfully loaded 'deepfm_nvt' version 1
I1029 18:11:23.685851 2271 model_repository_manager.cc:1022] loading: deepfm_ens:1
I1029 18:11:23.787203 2271 model_repository_manager.cc:1183] successfully loaded 'deepfm_ens' version 1
I1029 18:11:23.787495 2271 server.cc:522] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I1029 18:11:23.787587 2271 server.cc:549] 
+---------+---------------------------------------------------------+--------------------------------------+
| Backend | Path                                                    | Config                               |
+---------+---------------------------------------------------------+--------------------------------------+
| hugectr | /opt/tritonserver/backends/hugectr/libtriton_hugectr.so | {"cmdline":{"ps":"/models/ps.json"}} |
| python  | /opt/tritonserver/backends/python/libtriton_python.so   | {}                                   |
+---------+---------------------------------------------------------+--------------------------------------+

I1029 18:11:23.787678 2271 server.cc:592] 
+------------+---------+--------+
| Model      | Version | Status |
+------------+---------+--------+
| deepfm     | 1       | READY  |
| deepfm_ens | 1       | READY  |
| deepfm_nvt | 1       | READY  |
+------------+---------+--------+

I1029 18:11:23.787821 2271 tritonserver.cc:1920] 
+----------------------------------+----------------------------------------------------------------------------------+
| Option                           | Value                                                                            |
+----------------------------------+----------------------------------------------------------------------------------+
| server_id                        | triton                                                                           |
| server_version                   | 2.15.0                                                                           |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) sch |
|                                  | edule_policy model_configuration system_shared_memory cuda_shared_memory binary_ |
|                                  | tensor_data statistics                                                           |
| model_repository_path[0]         | /models                                                                          |
| model_control_mode               | MODE_NONE                                                                        |
| strict_model_config              | 1                                                                                |
| rate_limit                       | OFF                                                                              |
| pinned_memory_pool_byte_size     | 268435456                                                                        |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                         |
| cuda_memory_pool_byte_size{1}    | 67108864                                                                         |
| response_cache_byte_size         | 0                                                                                |
| min_supported_compute_capability | 6.0                                                                              |
| strict_readiness                 | 1                                                                                |
| exit_timeout                     | 30                                                                               |
+----------------------------------+----------------------------------------------------------------------------------+

I1029 18:11:23.790565 2271 grpc_server.cc:4117] Started GRPCInferenceService at 0.0.0.0:8001
I1029 18:11:23.791220 2271 http_server.cc:2815] Started HTTPService at 0.0.0.0:8000
I1029 18:11:23.834696 2271 http_server.cc:167] Started Metrics Service at 0.0.0.0:8002