{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7086876-72ed-4ac8-aeba-f05dbc641798",
   "metadata": {},
   "source": [
    "# Training Large Deep Learning Recommender Models with NVIDIA HugeCTR and Vertex AI Training\n",
    "\n",
    "This notebook demonstrates how to use Vertex AI Training to operationalize training and hyperparameter tuning of large scale deep learning models developed with NVIDIA HugeCTR framework.\n",
    "\n",
    "The notebook compiles prescriptive guidance for the following tasks:\n",
    "\n",
    "- Building a custom Vertex training container derived from NVIDIA NGC Merlin Training image\n",
    "- Configuring, submitting and monitoring a Vertex custom training job\n",
    "- Configuring, submitting and monitoring a Vertex hyperparameter tuning job\n",
    "- Retrieving and analyzing results of a hyperparameter tuning job\n",
    "\n",
    "The deep learning model used in this sample is [DeepFM](https://arxiv.org/abs/1703.04247) - a Factorization-Machine based Neural Network for CTR Prediction. The HugeCTR implementation of this model used in this notebook has been configured for the [Criteo dataset](https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/). \n",
    "\n",
    "## Model implementation\n",
    "\n",
    "[HugeCTR](https://github.com/NVIDIA-Merlin/HugeCTR) is NVIDIA's GPU-accelerated, highly scalable recommender framework. We highly encourage reviewing the [HugeCTR User Guide](https://github.com/NVIDIA-Merlin/HugeCTR/blob/master/docs/hugectr_user_guide.md) before proceeding with this notebook.\n",
    "\n",
    "NVIDIA HugeCTR facilitates highly scalable implementations of leading deep learning recommender models including Google's [Wide and Deep](https://arxiv.org/abs/1606.07792), Facebook's [DLRM](https://ai.facebook.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/), and the [DeepFM](https://arxiv.org/abs/1703.04247) model used in this notebook.\n",
    "\n",
    "A unique feature of HugeCTR is support for model-parallel embedding tables. Applying model-parallelizm for embedding tables enables massive scalability. Industrial grade deep learning recommendation systems most often employ very large embedding tables. User and item embedding tables - cornerstones of any recommender - can easily exceed tens of millions of rows. Without model-parallelizm it would be impossible to fit embedding tables this large in the memory of a single device - especially when using large embeddng vectors. In HugeCTR, embedding tables can span device memory across multiple GPUs on a single node or even across GPUs in a large distributed cluster. \n",
    "\n",
    "HugeCTR supports multiple model-parallelizm configurations for embedding tables. Refer to [the HugeCTR API reference](https://github.com/NVIDIA-Merlin/HugeCTR/blob/master/docs/hugectr_layer_book.md#embedding-types-detail) for detailed descriptions. In the DeepFM implementation used in this notebook, we utilize the `LocalizedSlotSparseEmbeddingHash` embedding type. In this embedding type, an embedding table is segmented into multiple slots or feature fields. Each slot stores embeddings for a single categorical feature. A given slot is allocated to a single GPU and it does not span multiple GPUs. However; in a multi GPU environment different slots can be allocated to different GPUs. \n",
    "\n",
    "The following diagram demonstrates an example configuration on a single node with multiple GPU - a hardware topology used by Vertex jobs in this notebook.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/deepfm.png\" alt=\"Model parallel embeddings\" />\n",
    "\n",
    "\n",
    "The Criteo dataset has 24 categorical features so there are 24 slots in the embedding table. Cardinalities of categorical variables vary from tens of milions to low teens so the dimensions of slots vary accordingly. Each slot in the embedding table utilizes an embedding vector of the same size. Note that the distribution of slots across GPUs is handled by HugeCTR; you don't have to explicitly pin a slot to a GPU.\n",
    "\n",
    "Dense layers of the DeepFM models are replicated on all GPUs using a canonical data-parallel pattern. \n",
    "\n",
    "You can find the code that implements the DeepFM model in the `src/training/hugectr/trainer/model.py` file. \n",
    "\n",
    "\n",
    "## Model training regimen\n",
    "\n",
    "The training regimen has been optimized for Vertex AI Training. \n",
    "- Google Cloud Storage (GCS) and Vertex Training GCS Fuse are used for accessing training and validation data\n",
    "- A single node, multiple GPUs worker pool is used for Vertex Training jobs.\n",
    "- Training code has been instrumented to support hyperparameter tuning using Vertex Training Hyperparameter Tuning Job. \n",
    "\n",
    "You can find the code that implements the training regimen in the `src/training/hugectr/trainer/task.py` file.\n",
    "\n",
    "### Training data access\n",
    "\n",
    "Large deep learning  recommender systems are trained on massive datasets often hundreds of terabytes in size. Maintaining high-throughput when streaming training data to GPU workers is of critical importance. HugeCTR features a highly efficient multi-threaded data reader that parallelizes data reading and model computations. The reader accesses training data through a file system interface. The reader cannot directly access object storage systems like Google Cloud Storage, which is a canonical storage system for large scale training and validation datasets in Vertex AI Training. To expose Google Cloud Storage through a file system interface, the notebook uses an integrated feature of Vertex AI  - Google Cloud Storage FUSE. Vertex AI GCS FUSE provides a high performance file system interface layer to GCS that is self-tuning and requires minimal configuration. The following diagram depicts the training data access configuration:\n",
    "\n",
    "<img src=\"./images/gcsfuse.png\" alt=\"GCS Fuse\" />\n",
    "\n",
    "\n",
    "### Vertex AI Training worker pool configuration\n",
    "\n",
    "HugeCTR supports both single node, multiple GPU configurations and multiple node, multiple GPU distributed cluster topologies. In this sample, we use a single node, multiple GPU configuration. Due to the computational complexity of modern deep learning recommender models we recommend using Vertex Training A2 series machines for large models implemented with HugeCTR. The A2 machines can be configured with up to 16 A100 GPUs, 96 vCPUs, and 1,360GBs RAM. Each A100 GPU has 40GB of device memory. These are powerful configurations that can handle complex models with large embeddings.\n",
    "\n",
    "In this sample we use the `a2-highgpu-4g` machine type. \n",
    "\n",
    "Both custom training and hyperparameter tuning Vertex AI jobs demonstrated in this notebook are configured to use a [custom training container](https://cloud.google.com/vertex-ai/docs/training/containers-overview). The container is a derivative of [NVIDIA NGC Merlin training container](https://ngc.nvidia.com/catalog/containers/nvidia:merlin:merlin-training). \n",
    "\n",
    "### HugeCTR hyperparameter tuning with Vertex AI\n",
    "\n",
    "The training module has been instrumented to support [hyperparameter tuning with Vertex AI](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview). The custom container includes the [cloudml-hypertune package](https://github.com/GoogleCloudPlatform/cloudml-hypertune), which is used to report the results of model evaluations to Vertex AI hypertuning service. The following diagram depicts a training flow implemeted by the training module.\n",
    "\n",
    "\n",
    "<img src=\"./images/hugectrtrainer.png\" alt=\"Training regimen\" style=\"height:15%; width:40%\"/>\n",
    "\n",
    "\n",
    "Note that as of HugeCTR v3.2 release, the `hugectr.inference.InferenceSession.evaluate` method used in the trainer module only supports the *AUC* evaluation metric.\n",
    "\n",
    "\n",
    "## Notebook flow\n",
    "\n",
    "This notebook assumes that the Criteo dataset has been preprocessed using the preprocessing workflow detailed in the `01-dataset-preprocessing.ipynb` notebook and the resulting Parquet training and validation splits, and processed data schema have been stored in Google Cloud Storage.\n",
    "\n",
    "As you walk through the notebook you will execute the following steps:\n",
    "- Configure notebook environment settings like GCP project, compute region, and the GCS locations of training and validation data splits.\n",
    "- Build a custom Vertex training container based on NVIDIA NGC Merlin Training container\n",
    "- Configure and submit a Vertex custom training job\n",
    "- Configure and submit a Vertex hyperparameter training job\n",
    "- Retrieve the results of the hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c99e2d-7d03-47a1-92ba-ed4630af19a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c864e5c-0319-4a2e-804b-fcac44e7e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import nvtabular as nvt\n",
    "import shutil\n",
    "\n",
    "from nvtabular.columns.schema import ColumnSchema, Schema\n",
    "from nvtabular.tags import Tags\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ecf96d-4649-4772-bcc3-b6170f3f8c7e",
   "metadata": {},
   "source": [
    "## Configure notebook settings\n",
    "### Set project, region, and Vertex AI settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb263c2-b3c2-4739-911c-cc88470241bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "\n",
    "VERTEX_STAGING_BUCKET = 'gs://jk-vertex-merlin'\n",
    "VERTEX_SA = 'vertex-sa@jk-mlops-dev.iam.gserviceaccount.com'\n",
    "LOCAL_STAGING_PATH = '/home/jupyter/staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0720d5f-a368-4c44-b31e-f3869f02ec39",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6370bb-96a3-4432-8899-3b4b723fe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=VERTEX_STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845048c6-68cf-435b-8ef5-8a3281c8632d",
   "metadata": {},
   "source": [
    "### Prepare a local staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8838523-b876-4d44-8598-8afc0f929e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(LOCAL_STAGING_PATH):\n",
    "    shutil.rmtree(LOCAL_STAGING_PATH)\n",
    "os.makedirs(LOCAL_STAGING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acbbf50-4e97-4f52-b957-4cc07601bbfb",
   "metadata": {},
   "source": [
    "### Set paths to training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795531fb-258c-401b-9f9d-0e30b3846bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'gs://jk-criteo-bucket/criteo_processed_parquet'\n",
    "TRAIN_DATA = f'{DATA_ROOT}/train/_file_list.txt'\n",
    "VALID_DATA = f'{DATA_ROOT}/valid/_file_list.txt'\n",
    "SCHEMA_PATH = f'{DATA_ROOT}/train/schema.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69c76b-9720-4168-8073-243d9d9ae06b",
   "metadata": {},
   "source": [
    "## Submit a Vertex custom training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de3552-4302-4d07-a830-3aeb1bdf4ca8",
   "metadata": {},
   "source": [
    "### Prepare a custom training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08f9980-ab36-4879-ab09-8df702032912",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = 'hugectr_deepfm'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT}/{IMAGE_NAME}'\n",
    "DOCKERFILE = 'src/Dockerfile.hugectr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad9f5ac6-0372-4601-a209-9b4a0123c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! gcloud builds submit --tag {IMAGE_URI} {DOCKERFILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546fe200-8638-4cda-936f-bd091a2c9cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  476.7kB\n",
      "Step 1/4 : FROM nvcr.io/nvidia/merlin/merlin-training:21.09\n",
      " ---> 8f6ef763d770\n",
      "Step 2/4 : RUN pip3 install cloudml-hypertune\n",
      " ---> Using cache\n",
      " ---> 7be51676d034\n",
      "Step 3/4 : WORKDIR /src\n",
      " ---> Using cache\n",
      " ---> 8e80619f2291\n",
      "Step 4/4 : COPY training/hugectr/ ./\n",
      " ---> Using cache\n",
      " ---> 623c6915619a\n",
      "Successfully built 623c6915619a\n",
      "Successfully tagged gcr.io/jk-mlops-dev/hugectr_deepfm:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t {IMAGE_URI} -f {DOCKERFILE} src\n",
    "!docker push {IMAGE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c8bd9-01f0-470e-8031-c72fabeae6ac",
   "metadata": {},
   "source": [
    "### Configure a custom training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111e199-25ff-42b9-aac5-875ca32cd8a2",
   "metadata": {},
   "source": [
    "#### Retrieve cardinalities for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9719b18b-fedf-40d3-8f4a-5f59b38d0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jk-criteo-bucket/criteo_processed_parquet/train/schema.pbtxt...\n",
      "/ [1 files][ 20.8 KiB/ 20.8 KiB]                                                \n",
      "Operation completed over 1 objects/20.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "LOCAL_SCHEMA_PATH = f'{LOCAL_STAGING_PATH}/schema.pbtxt'\n",
    "\n",
    "!gsutil cp {SCHEMA_PATH} {LOCAL_SCHEMA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ac85ff7-8dd0-4692-9c48-d8c255ce75af",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema.load_protobuf(LOCAL_SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f048e4-0846-4a93-84c9-677258220741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1': 18792578.0,\n",
       " 'C2': 35176.0,\n",
       " 'C3': 17091.0,\n",
       " 'C4': 7383.0,\n",
       " 'C5': 20154.0,\n",
       " 'C6': 4.0,\n",
       " 'C7': 7075.0,\n",
       " 'C8': 1403.0,\n",
       " 'C9': 63.0,\n",
       " 'C10': 12687136.0,\n",
       " 'C11': 1054830.0,\n",
       " 'C12': 297377.0,\n",
       " 'C13': 11.0,\n",
       " 'C14': 2209.0,\n",
       " 'C15': 10933.0,\n",
       " 'C16': 113.0,\n",
       " 'C17': 4.0,\n",
       " 'C18': 972.0,\n",
       " 'C19': 15.0,\n",
       " 'C20': 19550853.0,\n",
       " 'C21': 5602712.0,\n",
       " 'C22': 16779972.0,\n",
       " 'C23': 375290.0,\n",
       " 'C24': 12292.0,\n",
       " 'C25': 101.0,\n",
       " 'C26': 35.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_cardinalities(schema):\n",
    "    cardinalities = {key: value.properties['embedding_sizes']['cardinality'] \n",
    "                     for key, value in schema.column_schemas.items()\n",
    "                     if Tags.CATEGORICAL in value.tags}\n",
    "    \n",
    "    return cardinalities\n",
    "    \n",
    "    \n",
    "cardinalities = retrieve_cardinalities(schema)\n",
    "cardinalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc7c50-571b-4681-8dfe-afbbf7a4b78f",
   "metadata": {},
   "source": [
    "#### Set HugeCTR model and trainer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae824e81-12ce-4281-b856-7b3149dbab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODULE = 'trainer.task'\n",
    "\n",
    "NUM_EPOCHS = 0\n",
    "MAX_ITERATIONS = 50000\n",
    "EVAL_INTERVAL = 1000\n",
    "EVAL_BATCHES = 500\n",
    "EVAL_BATCHES_FINAL = 2500\n",
    "DISPLAY_INTERVAL = 200\n",
    "SNAPSHOT_INTERVAL = 0\n",
    "WORKSPACE_SIZE_PER_GPU = 61\n",
    "PER_GPU_BATCHSIZE = 2048\n",
    "LR = 0.001\n",
    "DROPOUT_RATE = 0.5\n",
    "NUM_WORKERS = 12\n",
    "SLOT_SIZE_ARRAY = json.dumps(\n",
    "    [int(cardinality) for cardinality in cardinalities.values()]).replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa0148-c742-49e3-9e7e-758ab513d555",
   "metadata": {},
   "source": [
    "#### Set training node configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcdcf631-d25a-4190-9429-1c19ad70ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'a2-highgpu-4g'\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "ACCELERATOR_NUM = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece569ba-9faf-46ff-be12-4ae1c64af83b",
   "metadata": {},
   "source": [
    "#### Configure worker pool specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a5bfc83-506a-459a-89d9-6a6963722a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = PER_GPU_BATCHSIZE * ACCELERATOR_NUM\n",
    "gpus = json.dumps([list(range(ACCELERATOR_NUM))]).replace(' ','')\n",
    "                 \n",
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [\"python\", \"-m\", TRAINING_MODULE],\n",
    "            \"args\": [\n",
    "                '--batchsize=' + str(batchsize),\n",
    "                '--train_data=' + TRAIN_DATA.replace('gs://', '/gcs/'), \n",
    "                '--valid_data=' + VALID_DATA.replace('gs://', '/gcs/'),\n",
    "                '--slot_size_array=' + SLOT_SIZE_ARRAY,\n",
    "                '--max_iter=' + str(MAX_ITERATIONS),\n",
    "                '--max_eval_batches=' + str(EVAL_BATCHES),\n",
    "                '--eval_batches=' + str(EVAL_BATCHES_FINAL),\n",
    "                '--dropout_rate=' + str(DROPOUT_RATE),\n",
    "                '--lr=' + str(LR),\n",
    "                '--num_workers=' + str(NUM_WORKERS),\n",
    "                '--num_epochs=' + str(NUM_EPOCHS),\n",
    "                '--eval_interval=' + str(EVAL_INTERVAL),\n",
    "                '--snapshot=' + str(SNAPSHOT_INTERVAL),\n",
    "                '--display_interval=' + str(DISPLAY_INTERVAL),\n",
    "                '--workspace_size_per_gpu=' + str(WORKSPACE_SIZE_PER_GPU),\n",
    "                '--gpus=' + gpus,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9e340-5733-42fe-bceb-8d338e31bec0",
   "metadata": {},
   "source": [
    "### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1301906-919b-4dc7-af5c-402e19c8b879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/6150234838197600256\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/6150234838197600256')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6150234838197600256?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6150234838197600256 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob run completed. Resource name: projects/895222332033/locations/us-central1/customJobs/6150234838197600256\n"
     ]
    }
   ],
   "source": [
    "job_name = 'HUGECTR_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{VERTEX_STAGING_BUCKET}/job_dir/{job_name}'\n",
    "\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "job.run(\n",
    "    sync=True,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68064a1a-c71a-4b86-82a4-7a723c0b55e2",
   "metadata": {},
   "source": [
    "## Submit and monitor a Vertex hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704e299-c23f-4a3c-a097-2ba3ce42e5b9",
   "metadata": {},
   "source": [
    "### Configure a hyperparameter job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353bdec-e3e7-410a-a723-8c002f3c4f57",
   "metadata": {},
   "source": [
    "#### Set HugeCTR model and trainer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20ce01-d020-4d8a-bdf0-0102bd9d5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODULE = 'trainer.task'\n",
    "\n",
    "NUM_EPOCHS = 0\n",
    "MAX_ITERATIONS = 10000\n",
    "EVAL_INTERVAL = 1000\n",
    "EVAL_BATCHES = 500\n",
    "EVAL_BATCHES_FINAL = 2500\n",
    "DISPLAY_INTERVAL = 200\n",
    "SNAPSHOT_INTERVAL = 0\n",
    "WORKSPACE_SIZE_PER_GPU = 61\n",
    "PER_GPU_BATCHSIZE = 2048\n",
    "NUM_WORKERS = 12\n",
    "SLOT_SIZE_ARRAY = json.dumps(\n",
    "    [int(cardinality) for cardinality in cardinalities.values()]).replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc77717-8200-40d4-a093-7a9204bcebd8",
   "metadata": {},
   "source": [
    "#### Set training node configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813368a-4e56-4753-9a25-ea068565a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'a2-highgpu-4g'\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "ACCELERATOR_NUM = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac41445-6dc1-45e5-bc17-98667056af2f",
   "metadata": {},
   "source": [
    "#### Configure worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db43af-3ed1-47ee-baca-e17677f7e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = PER_GPU_BATCHSIZE * ACCELERATOR_NUM\n",
    "gpus = json.dumps([list(range(ACCELERATOR_NUM))]).replace(' ','')\n",
    "                 \n",
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [\"python\", \"-m\", TRAINING_MODULE],\n",
    "            \"args\": [\n",
    "                '--batchsize=' + str(batchsize),\n",
    "                '--train_data=' + TRAIN_DATA.replace('gs://', '/gcs/'), \n",
    "                '--valid_data=' + VALID_DATA.replace('gs://', '/gcs/'),\n",
    "                '--slot_size_array=' + SLOT_SIZE_ARRAY,\n",
    "                '--max_iter=' + str(MAX_ITERATIONS),\n",
    "                '--max_eval_batches=' + str(EVAL_BATCHES),\n",
    "                '--eval_batches=' + str(EVAL_BATCHES_FINAL),\n",
    "                '--num_workers=' + str(NUM_WORKERS),\n",
    "                '--num_epochs=' + str(NUM_EPOCHS),\n",
    "                '--eval_interval=' + str(EVAL_INTERVAL),\n",
    "                '--snapshot=' + str(SNAPSHOT_INTERVAL),\n",
    "                '--display_interval=' + str(DISPLAY_INTERVAL),\n",
    "                '--workspace_size_per_gpu=' + str(WORKSPACE_SIZE_PER_GPU),\n",
    "                '--gpus=' + gpus,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507bcd7-7789-4630-b4c6-69d0c8aa9c93",
   "metadata": {},
   "source": [
    "#### Configure hyperparameter and metric specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0425cdf-07bc-4cf5-b3f7-858fdbc40fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_spec = {'AUC': 'maximize'}\n",
    "\n",
    "parameter_spec = {\n",
    "    'lr': hpt.DoubleParameterSpec(min=0.001, max=0.01, scale='log'),\n",
    "    'dropout_rate': hpt.DiscreteParameterSpec(values=[0.4, 0.5, 0.6], scale=None),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbadf45-f41b-4c99-a620-fd73062b072d",
   "metadata": {},
   "source": [
    "### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00435e4d-6833-4034-9bad-e2f46a1c75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'HUGECTR_HTUNING_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{VERTEX_STAGING_BUCKET}/job_dir/{job_name}'\n",
    "\n",
    "\n",
    "custom_job = aiplatform.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "\n",
    "hp_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=job_name,\n",
    "    custom_job=custom_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=4,\n",
    "    parallel_trial_count=2,\n",
    "    search_algorithm=None)\n",
    "\n",
    "hp_job.run(\n",
    "    sync=True,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832fbaa-f32e-4bac-b53b-5b0639cd28bc",
   "metadata": {},
   "source": [
    "### Retrieve trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcda9bf-3c5e-48ee-a75c-8dc197f96c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_job.trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f589c-4fc2-4a85-a56a-d099abb1853a",
   "metadata": {},
   "source": [
    "#### Find the best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e15b4-e033-42d8-9363-848d69557102",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = sorted(hp_job.trials, \n",
    "                    key=lambda trial: trial.final_measurement.metrics[0].value, \n",
    "                    reverse=True)[0]\n",
    "\n",
    "print(\"Best trial ID:\", best_trial.id)\n",
    "print(\"   AUC:\", best_trial.final_measurement.metrics[0].value)\n",
    "print(\"   LR:\", best_trial.parameters[1].value)\n",
    "print(\"   Dropout rate:\", best_trial.parameters[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a992c6c-285b-4fc6-b8c2-1eb2d63beefb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m80"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
