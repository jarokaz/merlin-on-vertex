{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7086876-72ed-4ac8-aeba-f05dbc641798",
   "metadata": {},
   "source": [
    "# Training an NVIDIA HugeCTR model with Vertex AI Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "526710d8-9cf9-4912-9ccb-c997fddb6d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n"
     ]
    }
   ],
   "source": [
    "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c864e5c-0319-4a2e-804b-fcac44e7e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import nvtabular as nvt\n",
    "import shutil\n",
    "\n",
    "from nvtabular.columns.schema import ColumnSchema, Schema\n",
    "from nvtabular.tags import Tags\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ecf96d-4649-4772-bcc3-b6170f3f8c7e",
   "metadata": {},
   "source": [
    "## Configure environment settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb263c2-b3c2-4739-911c-cc88470241bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "GCS_BUCKET = 'gs://jk-vertex-merlin'\n",
    "LOCAL_STAGING_PATH = '/home/jupyter/staging'\n",
    "VERTEX_SA = 'vertex-sa@jk-mlops-dev.iam.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8838523-b876-4d44-8598-8afc0f929e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(LOCAL_STAGING_PATH):\n",
    "    shutil.rmtree(LOCAL_STAGING_PATH)\n",
    "os.makedirs(LOCAL_STAGING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0f0e3-cc86-4474-b787-49e405852170",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732ddbb1-bdf6-4cbc-bdca-3554eb70e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=GCS_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de3552-4302-4d07-a830-3aeb1bdf4ca8",
   "metadata": {},
   "source": [
    "## Prepare a custom training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08f9980-ab36-4879-ab09-8df702032912",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = 'hugectr_deepfm'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT}/{IMAGE_NAME}'\n",
    "DOCKERFILE = 'src/training/hugectr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad9f5ac6-0372-4601-a209-9b4a0123c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! gcloud builds submit --tag {IMAGE_URI} {DOCKERFILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546fe200-8638-4cda-936f-bd091a2c9cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  84.99kB\n",
      "Step 1/4 : FROM nvcr.io/nvidia/merlin/merlin-training:21.09\n",
      " ---> 8f6ef763d770\n",
      "Step 2/4 : RUN pip3 install cloudml-hypertune\n",
      " ---> Using cache\n",
      " ---> ab2a50ff26f5\n",
      "Step 3/4 : WORKDIR /src\n",
      " ---> Using cache\n",
      " ---> ca01d83e287f\n",
      "Step 4/4 : COPY trainer ./trainer\n",
      " ---> Using cache\n",
      " ---> c1952f8801bc\n",
      "Successfully built c1952f8801bc\n",
      "Successfully tagged gcr.io/jk-mlops-dev/hugectr_deepfm:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t {IMAGE_URI} {DOCKERFILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8d41df-99af-484e-8f4c-a99327c83125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/hugectr_deepfm]\n",
      "\n",
      "\u001b[1B8420156d: Preparing \n",
      "\u001b[1Bd791a71c: Preparing \n",
      "\u001b[1B36e180cd: Preparing \n",
      "\u001b[1B1f36f93d: Preparing \n",
      "\u001b[1Be0fa48ac: Preparing \n",
      "\u001b[1Bd4cd8fbb: Preparing \n",
      "\u001b[1B2cf6a026: Preparing \n",
      "\u001b[1B26a95f43: Preparing \n",
      "\u001b[1Bba5d6668: Preparing \n",
      "\u001b[1Ba9641b18: Preparing \n",
      "\u001b[1B42012c23: Preparing \n",
      "\u001b[1Bbd3e801f: Preparing \n",
      "\u001b[1B7039f00c: Preparing \n",
      "\u001b[1B023e019c: Preparing \n",
      "\u001b[1Bf9e4afbc: Preparing \n",
      "\u001b[1Be9115178: Preparing \n",
      "\u001b[1B220871e3: Preparing \n",
      "\u001b[1B76810591: Preparing \n",
      "\u001b[1B7b7db32e: Preparing \n",
      "\u001b[1B176606fb: Preparing \n",
      "\u001b[1B44765ddc: Preparing \n",
      "\u001b[1B295911d7: Preparing \n",
      "\u001b[1B1a643992: Preparing \n",
      "\u001b[1B6f8bf009: Preparing \n",
      "\u001b[20B4cd8fbb: Waiting g \n",
      "\u001b[1Bd0bdb6b2: Preparing \n",
      "\u001b[15B039f00c: Waiting g \n",
      "\u001b[14B9e4afbc: Waiting g \n",
      "\u001b[1B3c6245a7: Preparing \n",
      "\u001b[14B20871e3: Waiting g \n",
      "\u001b[23Ba5d6668: Waiting g \n",
      "\u001b[1B31c5510f: Preparing \n",
      "\u001b[7B59647bc1: Waiting g \n",
      "\u001b[11Bf8bf009: Waiting g \n",
      "\u001b[14B95911d7: Waiting g \n",
      "\u001b[8B3c6245a7: Waiting g \n",
      "\u001b[1B58a72969: Preparing \n",
      "\u001b[21B6810591: Waiting g \n",
      "\u001b[1B109a3ea2: Preparing \n",
      "\u001b[3Bcb179a54: Waiting g \n",
      "\u001b[3B109a3ea2: Waiting g \n",
      "\u001b[1B7e454744: Preparing \n",
      "\u001b[8B6fc769b7: Waiting g \n",
      "\u001b[4Bdeda2561: Waiting g \n",
      "\u001b[4B7e454744: Waiting g \n",
      "\u001b[3Bcec9ff49: Waiting g \n",
      "\u001b[3B15c2b3a3: Waiting g \n",
      "\u001b[1B1b9afbae: Preparing \n",
      "\u001b[3Bc8e05279: Waiting g \n",
      "\u001b[1B60182953: Preparing \n",
      "\u001b[4B1b9afbae: Waiting g \n",
      "\u001b[3B60182953: Waiting g \n",
      "\u001b[8Bd1994cdb: Waiting g \n",
      "\u001b[1B9c95fe1b: Preparing \n",
      "\u001b[1B67ddabfb: Preparing \n",
      "\u001b[5B4b4d2292: Waiting g \n",
      "\u001b[1B6513dba7: Preparing \n",
      "\u001b[5B9c95fe1b: Waiting g \n",
      "\u001b[4B664f5ac5: Waiting g \n",
      "\u001b[1B316378c2: Preparing \n",
      "\u001b[3B35ff9141: Waiting g \n",
      "\u001b[1Bf3851c58: Preparing \n",
      "\u001b[1B1910be43: Preparing \n",
      "\u001b[3Bf3851c58: Waiting g \n",
      "\u001b[3B1910be43: Waiting g \n",
      "\u001b[3B4e358856: Waiting g \n",
      "\u001b[1Bd201b9e7: Preparing \n",
      "\u001b[3Bef23fc52: Waiting g \n",
      "\u001b[1B4116b86d: Preparing \n",
      "\u001b[4Bd201b9e7: Waiting g \n",
      "\u001b[1Be5379d4b: Preparing \n",
      "\u001b[5Bc6572b32: Waiting g \n",
      "\u001b[1B73877dab: Preparing \n",
      "\u001b[5Ba3065d69: Waiting g \n",
      "\u001b[3B73877dab: Waiting g \n",
      "\u001b[3Bf42fb8d5: Waiting g \n",
      "\u001b[1B37aa9a0a: Preparing \n",
      "\u001b[4B19677a82: Waiting g \n",
      "\u001b[1B518e20b0: Preparing \n",
      "\u001b[4B37aa9a0a: Waiting g \n",
      "\u001b[1B5d7876c0: Preparing \n",
      "\u001b[1Bf6dd0bf3: Preparing \n",
      "\u001b[2Bf6dd0bf3: Waiting g \n",
      "\u001b[1B96a127ae: Preparing \n",
      "\u001b[1Bf69cc2e7: Preparing \n",
      "\u001b[4B7995c44f: Waiting g \n",
      "\u001b[4B96a127ae: Layer already exists \u001b[82A\u001b[2K\u001b[77A\u001b[2K\u001b[71A\u001b[2K\u001b[67A\u001b[2K\u001b[69A\u001b[2K\u001b[60A\u001b[2K\u001b[53A\u001b[2K\u001b[49A\u001b[2K\u001b[44A\u001b[2K\u001b[39A\u001b[2K\u001b[33A\u001b[2K\u001b[28A\u001b[2K\u001b[22A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2Klatest: digest: sha256:f08b195c038374cd942729806f3544f9f6fb13286c2c54281d3c27da1800a1c7 size: 18609\n"
     ]
    }
   ],
   "source": [
    "!docker push {IMAGE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ab5dd-3624-4fd6-adcc-2d0a722999c1",
   "metadata": {},
   "source": [
    "## Configure a training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031de3e7-fcbe-4f74-b069-0a6554318c81",
   "metadata": {},
   "source": [
    "### Set paths to training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23092bdf-b847-4f98-9da7-09480ddbacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'gs://jk-criteo-bucket/criteo_processed_parquet'\n",
    "TRAIN_DATA = f'{DATA_ROOT}/train/_file_list.txt'\n",
    "VALID_DATA = f'{DATA_ROOT}/valid/_file_list.txt'\n",
    "SCHEMA_PATH = f'{DATA_ROOT}/train/schema.pbtxt'\n",
    "FITTED_WORKFLOW_PATH = f'{DATA_ROOT}/workflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111e199-25ff-42b9-aac5-875ca32cd8a2",
   "metadata": {},
   "source": [
    "### Retrieve cardinalities for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9719b18b-fedf-40d3-8f4a-5f59b38d0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jk-criteo-bucket/criteo_processed_parquet/train/schema.pbtxt...\n",
      "/ [1 files][ 20.8 KiB/ 20.8 KiB]                                                \n",
      "Operation completed over 1 objects/20.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "LOCAL_SCHEMA_PATH = f'{LOCAL_STAGING_PATH}/schema.pbtxt'\n",
    "\n",
    "!gsutil cp {SCHEMA_PATH} {LOCAL_SCHEMA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac85ff7-8dd0-4692-9c48-d8c255ce75af",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema.load_protobuf(LOCAL_SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93f048e4-0846-4a93-84c9-677258220741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1': 18792578.0,\n",
       " 'C2': 35176.0,\n",
       " 'C3': 17091.0,\n",
       " 'C4': 7383.0,\n",
       " 'C5': 20154.0,\n",
       " 'C6': 4.0,\n",
       " 'C7': 7075.0,\n",
       " 'C8': 1403.0,\n",
       " 'C9': 63.0,\n",
       " 'C10': 12687136.0,\n",
       " 'C11': 1054830.0,\n",
       " 'C12': 297377.0,\n",
       " 'C13': 11.0,\n",
       " 'C14': 2209.0,\n",
       " 'C15': 10933.0,\n",
       " 'C16': 113.0,\n",
       " 'C17': 4.0,\n",
       " 'C18': 972.0,\n",
       " 'C19': 15.0,\n",
       " 'C20': 19550853.0,\n",
       " 'C21': 5602712.0,\n",
       " 'C22': 16779972.0,\n",
       " 'C23': 375290.0,\n",
       " 'C24': 12292.0,\n",
       " 'C25': 101.0,\n",
       " 'C26': 35.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_cardinalities(schema):\n",
    "    cardinalities = {key: value.properties['embedding_sizes']['cardinality'] \n",
    "                     for key, value in schema.column_schemas.items()\n",
    "                     if Tags.CATEGORICAL in value.tags}\n",
    "    \n",
    "    return cardinalities\n",
    "    \n",
    "    \n",
    "cardinalities = retrieve_cardinalities(schema)\n",
    "cardinalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff692b09-ce86-4116-a843-fd8c1b107f48",
   "metadata": {},
   "source": [
    "### Configure worker pools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681050d-bebc-45cd-93a5-161bc02e2269",
   "metadata": {},
   "source": [
    "#### Training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13d5356c-161f-44b8-8329-bb5dfed004d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODULE = 'trainer.task'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc7c50-571b-4681-8dfe-afbbf7a4b78f",
   "metadata": {},
   "source": [
    "#### HugeCTR model and trainer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae824e81-12ce-4281-b856-7b3149dbab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 0\n",
    "MAX_ITERATIONS = 100000\n",
    "EVAL_INTERVAL = 1000\n",
    "EVAL_BATCHES = 500\n",
    "EVAL_BATCHES_FINAL = 2500\n",
    "DISPLAY_INTERVAL = 200\n",
    "SNAPSHOT_INTERVAL = 0\n",
    "WORKSPACE_SIZE_PER_GPU = 61\n",
    "PER_GPU_BATCHSIZE = 2048\n",
    "LR = 0.001\n",
    "DROPOUT_RATE = 0.5\n",
    "NUM_WORKERS = 12\n",
    "SLOT_SIZE_ARRAY = json.dumps(\n",
    "    [int(cardinality) for cardinality in cardinalities.values()]).replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa0148-c742-49e3-9e7e-758ab513d555",
   "metadata": {},
   "source": [
    "#### Training node configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcdcf631-d25a-4190-9429-1c19ad70ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'a2-highgpu-4g'\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "ACCELERATOR_NUM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "253e58ad-d6ac-4c73-9775-754189a3d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'a2-highgpu-4g'\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "ACCELERATOR_NUM = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece569ba-9faf-46ff-be12-4ae1c64af83b",
   "metadata": {},
   "source": [
    "#### Worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a5bfc83-506a-459a-89d9-6a6963722a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = PER_GPU_BATCHSIZE * ACCELERATOR_NUM\n",
    "gpus = json.dumps([list(range(ACCELERATOR_NUM))]).replace(' ','')\n",
    "                 \n",
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [\"python\", \"-m\", TRAINING_MODULE],\n",
    "            \"args\": [\n",
    "                '--batchsize=' + str(batchsize),\n",
    "                '--train_data=' + TRAIN_DATA.replace('gs://', '/gcs/'), \n",
    "                '--valid_data=' + VALID_DATA.replace('gs://', '/gcs/'),\n",
    "                '--slot_size_array=' + SLOT_SIZE_ARRAY,\n",
    "                '--max_iter=' + str(MAX_ITERATIONS),\n",
    "                '--max_eval_batches=' + str(EVAL_BATCHES),\n",
    "                '--eval_batches=' + str(EVAL_BATCHES_FINAL),\n",
    "                '--dropout_rate=' + str(DROPOUT_RATE),\n",
    "                '--lr=' + str(LR),\n",
    "                '--num_workers=' + str(NUM_WORKERS),\n",
    "                '--num_epochs=' + str(NUM_EPOCHS),\n",
    "                '--eval_interval=' + str(EVAL_INTERVAL),\n",
    "                '--snapshot=' + str(SNAPSHOT_INTERVAL),\n",
    "                '--display_interval=' + str(DISPLAY_INTERVAL),\n",
    "                '--workspace_size_per_gpu=' + str(WORKSPACE_SIZE_PER_GPU),\n",
    "                '--gpus=' + gpus,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9e340-5733-42fe-bceb-8d338e31bec0",
   "metadata": {},
   "source": [
    "## Submit and monitor a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1301906-919b-4dc7-af5c-402e19c8b879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/4798156593428430848\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/4798156593428430848')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4798156593428430848?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/4798156593428430848 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/4798156593428430848 current state:\n",
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "job_name = 'HUGECTR_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{GCS_BUCKET}/job_dir/{job_name}'\n",
    "\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "job.run(\n",
    "    sync=True,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f39296-bccc-42b1-803c-a0fad3d66b16",
   "metadata": {},
   "source": [
    "### Review model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1a8032-7d1f-4809-b535-ca2509ea9ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobState.JOB_STATE_PENDING: 2>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/4798156593428430848 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/4798156593428430848 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/4798156593428430848 current state:\n",
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "job.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41474f04-0511-4633-896e-cef3fb986f3e",
   "metadata": {},
   "source": [
    "### Wait for the job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cc116-d25d-4293-8fab-b908fce2bb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68064a1a-c71a-4b86-82a4-7a723c0b55e2",
   "metadata": {},
   "source": [
    "## Submit and monitor a hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353bdec-e3e7-410a-a723-8c002f3c4f57",
   "metadata": {},
   "source": [
    "#### HugeCTR model and trainer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20ce01-d020-4d8a-bdf0-0102bd9d5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 0\n",
    "MAX_ITERATIONS = 10000\n",
    "EVAL_INTERVAL = 1000\n",
    "EVAL_BATCHES = 500\n",
    "EVAL_BATCHES_FINAL = 2500\n",
    "DISPLAY_INTERVAL = 200\n",
    "SNAPSHOT_INTERVAL = 0\n",
    "WORKSPACE_SIZE_PER_GPU = 61\n",
    "PER_GPU_BATCHSIZE = 2048\n",
    "NUM_WORKERS = 12\n",
    "SLOT_SIZE_ARRAY = json.dumps(\n",
    "    [int(cardinality) for cardinality in cardinalities.values()]).replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc77717-8200-40d4-a093-7a9204bcebd8",
   "metadata": {},
   "source": [
    "#### Training node configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce66309-584c-4300-bdca-07d609b7bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODULE = 'trainer.task'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e0e04-2000-46a9-83ad-c9c40e1d138a",
   "metadata": {},
   "source": [
    "#### Training node configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813368a-4e56-4753-9a25-ea068565a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'a2-highgpu-4g'\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "ACCELERATOR_NUM = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac41445-6dc1-45e5-bc17-98667056af2f",
   "metadata": {},
   "source": [
    "### Worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db43af-3ed1-47ee-baca-e17677f7e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = PER_GPU_BATCHSIZE * ACCELERATOR_NUM\n",
    "gpus = json.dumps([list(range(ACCELERATOR_NUM))]).replace(' ','')\n",
    "                 \n",
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [\"python\", \"-m\", TRAINING_MODULE],\n",
    "            \"args\": [\n",
    "                '--batchsize=' + str(batchsize),\n",
    "                '--train_data=' + TRAIN_DATA.replace('gs://', '/gcs/'), \n",
    "                '--valid_data=' + VALID_DATA.replace('gs://', '/gcs/'),\n",
    "                '--slot_size_array=' + SLOT_SIZE_ARRAY,\n",
    "                '--max_iter=' + str(MAX_ITERATIONS),\n",
    "                '--max_eval_batches=' + str(EVAL_BATCHES),\n",
    "                '--eval_batches=' + str(EVAL_BATCHES_FINAL),\n",
    "                #'--dropout_rate=' + str(DROPOUT_RATE),\n",
    "                #'--lr=' + str(LR),\n",
    "                '--num_workers=' + str(NUM_WORKERS),\n",
    "                '--num_epochs=' + str(NUM_EPOCHS),\n",
    "                '--eval_interval=' + str(EVAL_INTERVAL),\n",
    "                '--snapshot=' + str(SNAPSHOT_INTERVAL),\n",
    "                '--display_interval=' + str(DISPLAY_INTERVAL),\n",
    "                '--workspace_size_per_gpu=' + str(WORKSPACE_SIZE_PER_GPU),\n",
    "                '--gpus=' + gpus,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507bcd7-7789-4630-b4c6-69d0c8aa9c93",
   "metadata": {},
   "source": [
    "### Parameter and metric specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0425cdf-07bc-4cf5-b3f7-858fdbc40fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_spec = {'AUC': 'maximize'}\n",
    "\n",
    "parameter_spec = {\n",
    "    'lr': hpt.DoubleParameterSpec(min=0.001, max=0.01, scale='log'),\n",
    "    'dropout_rate': hpt.DiscreteParameterSpec(values=[0.4, 0.5, 0.6], scale=None),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbadf45-f41b-4c99-a620-fd73062b072d",
   "metadata": {},
   "source": [
    "### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00435e4d-6833-4034-9bad-e2f46a1c75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'HUGECTR_HTUNING_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{GCS_BUCKET}/job_dir/{job_name}'\n",
    "\n",
    "\n",
    "custom_job = aiplatform.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "\n",
    "hp_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=job_name,\n",
    "    custom_job=custom_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=4,\n",
    "    parallel_trial_count=2,\n",
    "    search_algorithm=None)\n",
    "\n",
    "hp_job.run(\n",
    "    sync=True,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832fbaa-f32e-4bac-b53b-5b0639cd28bc",
   "metadata": {},
   "source": [
    "### Retrieve trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcda9bf-3c5e-48ee-a75c-8dc197f96c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_job.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b0395-a7e2-48a2-9a15-d1c3646099c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_job.trials[0].final_measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639cfbb-2245-4940-a412-077fde0d637d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m80"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
