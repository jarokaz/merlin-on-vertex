{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7086876-72ed-4ac8-aeba-f05dbc641798",
   "metadata": {},
   "source": [
    "# Training an NVIDIA HugeCTR model with Vertex AI Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c864e5c-0319-4a2e-804b-fcac44e7e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import nvtabular as nvt\n",
    "import shutil\n",
    "\n",
    "from nvtabular.columns.schema import ColumnSchema, Schema\n",
    "from nvtabular.tags import Tags\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ecf96d-4649-4772-bcc3-b6170f3f8c7e",
   "metadata": {},
   "source": [
    "## Configure notebook settings\n",
    "### Set project, region, and Vertex AI settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb263c2-b3c2-4739-911c-cc88470241bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "\n",
    "VERTEX_STAGING_BUCKET = 'gs://jk-vertex-merlin'\n",
    "VERTEX_SA = 'vertex-sa@jk-mlops-dev.iam.gserviceaccount.com'\n",
    "LOCAL_STAGING_PATH = '/home/jupyter/staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0720d5f-a368-4c44-b31e-f3869f02ec39",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6370bb-96a3-4432-8899-3b4b723fe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=VERTEX_STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845048c6-68cf-435b-8ef5-8a3281c8632d",
   "metadata": {},
   "source": [
    "### Prepare a local staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8838523-b876-4d44-8598-8afc0f929e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(LOCAL_STAGING_PATH):\n",
    "    shutil.rmtree(LOCAL_STAGING_PATH)\n",
    "os.makedirs(LOCAL_STAGING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acbbf50-4e97-4f52-b957-4cc07601bbfb",
   "metadata": {},
   "source": [
    "### Set paths to training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795531fb-258c-401b-9f9d-0e30b3846bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'gs://jk-criteo-bucket/criteo_processed_parquet'\n",
    "TRAIN_DATA = f'{DATA_ROOT}/train/_file_list.txt'\n",
    "VALID_DATA = f'{DATA_ROOT}/valid/_file_list.txt'\n",
    "SCHEMA_PATH = f'{DATA_ROOT}/train/schema.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69c76b-9720-4168-8073-243d9d9ae06b",
   "metadata": {},
   "source": [
    "## Submit a Vertex custom training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de3552-4302-4d07-a830-3aeb1bdf4ca8",
   "metadata": {},
   "source": [
    "### Prepare a custom training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08f9980-ab36-4879-ab09-8df702032912",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = 'hugectr_deepfm'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT}/{IMAGE_NAME}'\n",
    "DOCKERFILE = 'src/training/hugectr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad9f5ac6-0372-4601-a209-9b4a0123c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! gcloud builds submit --tag {IMAGE_URI} {DOCKERFILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546fe200-8638-4cda-936f-bd091a2c9cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  97.28kB\n",
      "Step 1/4 : FROM nvcr.io/nvidia/merlin/merlin-training:21.09\n",
      " ---> 8f6ef763d770\n",
      "Step 2/4 : RUN pip3 install cloudml-hypertune\n",
      " ---> Using cache\n",
      " ---> 7be51676d034\n",
      "Step 3/4 : WORKDIR /src\n",
      " ---> Using cache\n",
      " ---> 8e80619f2291\n",
      "Step 4/4 : COPY trainer ./trainer\n",
      " ---> Using cache\n",
      " ---> b84e9d24f841\n",
      "Successfully built b84e9d24f841\n",
      "Successfully tagged gcr.io/jk-mlops-dev/hugectr_deepfm:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t {IMAGE_URI} {DOCKERFILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8d41df-99af-484e-8f4c-a99327c83125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/hugectr_deepfm]\n",
      "\n",
      "\u001b[1B0b00f7fb: Preparing \n",
      "\u001b[1B8170b157: Preparing \n",
      "\u001b[1B96e6939c: Preparing \n",
      "\u001b[1B1f36f93d: Preparing \n",
      "\u001b[1Be0fa48ac: Preparing \n",
      "\u001b[1Bd4cd8fbb: Preparing \n",
      "\u001b[1B2cf6a026: Preparing \n",
      "\u001b[1B26a95f43: Preparing \n",
      "\u001b[1Bba5d6668: Preparing \n",
      "\u001b[1Ba9641b18: Preparing \n",
      "\u001b[1B42012c23: Preparing \n",
      "\u001b[1Bbd3e801f: Preparing \n",
      "\u001b[1B7039f00c: Preparing \n",
      "\u001b[1B023e019c: Preparing \n",
      "\u001b[1Bf9e4afbc: Preparing \n",
      "\u001b[1Be9115178: Preparing \n",
      "\u001b[1B220871e3: Preparing \n",
      "\u001b[1B76810591: Preparing \n",
      "\u001b[1B7b7db32e: Preparing \n",
      "\u001b[1B176606fb: Preparing \n",
      "\u001b[1B44765ddc: Preparing \n",
      "\u001b[1B295911d7: Preparing \n",
      "\u001b[1B1a643992: Preparing \n",
      "\u001b[1B6f8bf009: Preparing \n",
      "\u001b[1Bd3ad3992: Preparing \n",
      "\u001b[1Bd0bdb6b2: Preparing \n",
      "\u001b[1B59647bc1: Preparing \n",
      "\u001b[1B9b0b029e: Preparing \n",
      "\u001b[1B3c6245a7: Preparing \n",
      "\u001b[1B9f6effa5: Preparing \n",
      "\u001b[1B43806c89: Preparing \n",
      "\u001b[1B31c5510f: Preparing \n",
      "\u001b[1B4c5d4460: Preparing \n",
      "\u001b[1Be3d1aa10: Preparing \n",
      "\u001b[1Bc1212f82: Preparing \n",
      "\u001b[1B6fc769b7: Preparing \n",
      "\u001b[1B58a72969: Preparing \n",
      "\u001b[1Bcb179a54: Preparing \n",
      "\u001b[1B109a3ea2: Preparing \n",
      "\u001b[35B4cd8fbb: Waiting g \n",
      "\u001b[1Bdeda2561: Preparing \n",
      "\u001b[1B7e454744: Preparing \n",
      "\u001b[37Bcf6a026: Waiting g \n",
      "\u001b[1Bcec9ff49: Preparing \n",
      "\u001b[1B15c2b3a3: Preparing \n",
      "\u001b[1Bd1994cdb: Preparing \n",
      "\u001b[40B6a95f43: Waiting g \n",
      "\u001b[1B1b9afbae: Preparing \n",
      "\u001b[41Ba5d6668: Waiting g \n",
      "\u001b[41B9641b18: Waiting g \n",
      "\u001b[1B823004fd: Preparing \n",
      "\u001b[1B4b4d2292: Preparing \n",
      "\u001b[43B2012c23: Waiting g \n",
      "\u001b[42B039f00c: Waiting g \n",
      "\u001b[1B67ddabfb: Preparing \n",
      "\u001b[33Bf8bf009: Waiting g \n",
      "\u001b[44B23e019c: Waiting g \n",
      "\u001b[1Bd47ab1c6: Preparing \n",
      "\u001b[30Bf6effa5: Waiting g \n",
      "\u001b[46B9e4afbc: Waiting g \n",
      "\u001b[31B3806c89: Waiting g \n",
      "\u001b[1Bf3851c58: Preparing \n",
      "\u001b[32B1c5510f: Waiting g \n",
      "\u001b[32Bc5d4460: Waiting g \n",
      "\u001b[41B3ad3992: Waiting g \n",
      "\u001b[18B4a6be62: Waiting g \n",
      "\u001b[34B3d1aa10: Waiting g \n",
      "\u001b[1Bc6572b32: Preparing \n",
      "\u001b[20B0182953: Waiting g \n",
      "\u001b[36B1212f82: Waiting g \n",
      "\u001b[44Bb0b029e: Waiting g \n",
      "\u001b[37Bfc769b7: Waiting g \n",
      "\u001b[1B73877dab: Preparing \n",
      "\u001b[23Bb4d2292: Waiting g \n",
      "\u001b[1B19677a82: Preparing \n",
      "\u001b[1B970605a9: Preparing \n",
      "\u001b[41B8a72969: Waiting g \n",
      "\u001b[59B76606fb: Waiting g \n",
      "\u001b[33B8e05279: Waiting g \n",
      "\u001b[37Bec9ff49: Waiting g \n",
      "\u001b[41Beda2561: Waiting g \n",
      "\u001b[62B4765ddc: Waiting g \n",
      "\u001b[1B7995c44f: Preparing \n",
      "\u001b[40B5c2b3a3: Waiting g \n",
      "\u001b[43B117f7ee: Waiting g \n",
      "\u001b[65B95911d7: Waiting g \n",
      "\u001b[66B95911d7: Pushed    45.2MB/44.98MB3A\u001b[2K\u001b[77A\u001b[2K\u001b[74A\u001b[2K\u001b[67A\u001b[2K\u001b[62A\u001b[2K\u001b[60A\u001b[2K\u001b[54A\u001b[2K\u001b[50A\u001b[2K\u001b[48A\u001b[2K\u001b[42A\u001b[2K\u001b[37A\u001b[2K\u001b[32A\u001b[2K\u001b[29A\u001b[2K\u001b[21A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[8A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[8A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2K\u001b[66A\u001b[2Klatest: digest: sha256:2f9645850395adcaf41250455b70effdccef67ae6bc700d1248892332d4dca06 size: 18610\n"
     ]
    }
   ],
   "source": [
    "!docker push {IMAGE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c8bd9-01f0-470e-8031-c72fabeae6ac",
   "metadata": {},
   "source": [
    "### Configure a custom training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111e199-25ff-42b9-aac5-875ca32cd8a2",
   "metadata": {},
   "source": [
    "#### Retrieve cardinalities for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9719b18b-fedf-40d3-8f4a-5f59b38d0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jk-criteo-bucket/criteo_processed_parquet/train/schema.pbtxt...\n",
      "/ [1 files][ 20.8 KiB/ 20.8 KiB]                                                \n",
      "Operation completed over 1 objects/20.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "LOCAL_SCHEMA_PATH = f'{LOCAL_STAGING_PATH}/schema.pbtxt'\n",
    "\n",
    "!gsutil cp {SCHEMA_PATH} {LOCAL_SCHEMA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ac85ff7-8dd0-4692-9c48-d8c255ce75af",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema.load_protobuf(LOCAL_SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f048e4-0846-4a93-84c9-677258220741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1': 18792578.0,\n",
       " 'C2': 35176.0,\n",
       " 'C3': 17091.0,\n",
       " 'C4': 7383.0,\n",
       " 'C5': 20154.0,\n",
       " 'C6': 4.0,\n",
       " 'C7': 7075.0,\n",
       " 'C8': 1403.0,\n",
       " 'C9': 63.0,\n",
       " 'C10': 12687136.0,\n",
       " 'C11': 1054830.0,\n",
       " 'C12': 297377.0,\n",
       " 'C13': 11.0,\n",
       " 'C14': 2209.0,\n",
       " 'C15': 10933.0,\n",
       " 'C16': 113.0,\n",
       " 'C17': 4.0,\n",
       " 'C18': 972.0,\n",
       " 'C19': 15.0,\n",
       " 'C20': 19550853.0,\n",
       " 'C21': 5602712.0,\n",
       " 'C22': 16779972.0,\n",
       " 'C23': 375290.0,\n",
       " 'C24': 12292.0,\n",
       " 'C25': 101.0,\n",
       " 'C26': 35.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_cardinalities(schema):\n",
    "    cardinalities = {key: value.properties['embedding_sizes']['cardinality'] \n",
    "                     for key, value in schema.column_schemas.items()\n",
    "                     if Tags.CATEGORICAL in value.tags}\n",
    "    \n",
    "    return cardinalities\n",
    "    \n",
    "    \n",
    "cardinalities = retrieve_cardinalities(schema)\n",
    "cardinalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc7c50-571b-4681-8dfe-afbbf7a4b78f",
   "metadata": {},
   "source": [
    "#### Set HugeCTR model and trainer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae824e81-12ce-4281-b856-7b3149dbab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODULE = 'trainer.task'\n",
    "\n",
    "NUM_EPOCHS = 0\n",
    "MAX_ITERATIONS = 50000\n",
    "EVAL_INTERVAL = 1000\n",
    "EVAL_BATCHES = 500\n",
    "EVAL_BATCHES_FINAL = 2500\n",
    "DISPLAY_INTERVAL = 200\n",
    "SNAPSHOT_INTERVAL = 0\n",
    "WORKSPACE_SIZE_PER_GPU = 61\n",
    "PER_GPU_BATCHSIZE = 2048\n",
    "LR = 0.001\n",
    "DROPOUT_RATE = 0.5\n",
    "NUM_WORKERS = 12\n",
    "SLOT_SIZE_ARRAY = json.dumps(\n",
    "    [int(cardinality) for cardinality in cardinalities.values()]).replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa0148-c742-49e3-9e7e-758ab513d555",
   "metadata": {},
   "source": [
    "#### Set training node configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcdcf631-d25a-4190-9429-1c19ad70ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'a2-highgpu-4g'\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "ACCELERATOR_NUM = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece569ba-9faf-46ff-be12-4ae1c64af83b",
   "metadata": {},
   "source": [
    "#### Configure worker pool specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a5bfc83-506a-459a-89d9-6a6963722a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = PER_GPU_BATCHSIZE * ACCELERATOR_NUM\n",
    "gpus = json.dumps([list(range(ACCELERATOR_NUM))]).replace(' ','')\n",
    "                 \n",
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [\"python\", \"-m\", TRAINING_MODULE],\n",
    "            \"args\": [\n",
    "                '--batchsize=' + str(batchsize),\n",
    "                '--train_data=' + TRAIN_DATA.replace('gs://', '/gcs/'), \n",
    "                '--valid_data=' + VALID_DATA.replace('gs://', '/gcs/'),\n",
    "                '--slot_size_array=' + SLOT_SIZE_ARRAY,\n",
    "                '--max_iter=' + str(MAX_ITERATIONS),\n",
    "                '--max_eval_batches=' + str(EVAL_BATCHES),\n",
    "                '--eval_batches=' + str(EVAL_BATCHES_FINAL),\n",
    "                '--dropout_rate=' + str(DROPOUT_RATE),\n",
    "                '--lr=' + str(LR),\n",
    "                '--num_workers=' + str(NUM_WORKERS),\n",
    "                '--num_epochs=' + str(NUM_EPOCHS),\n",
    "                '--eval_interval=' + str(EVAL_INTERVAL),\n",
    "                '--snapshot=' + str(SNAPSHOT_INTERVAL),\n",
    "                '--display_interval=' + str(DISPLAY_INTERVAL),\n",
    "                '--workspace_size_per_gpu=' + str(WORKSPACE_SIZE_PER_GPU),\n",
    "                '--gpus=' + gpus,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9e340-5733-42fe-bceb-8d338e31bec0",
   "metadata": {},
   "source": [
    "### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1301906-919b-4dc7-af5c-402e19c8b879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/219403147276189696\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/219403147276189696')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/219403147276189696?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/219403147276189696 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob run completed. Resource name: projects/895222332033/locations/us-central1/customJobs/219403147276189696\n"
     ]
    }
   ],
   "source": [
    "job_name = 'HUGECTR_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{VERTEX_STAGING_BUCKET}/job_dir/{job_name}'\n",
    "\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "job.run(\n",
    "    sync=True,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68064a1a-c71a-4b86-82a4-7a723c0b55e2",
   "metadata": {},
   "source": [
    "## Submit and monitor a Vertex hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704e299-c23f-4a3c-a097-2ba3ce42e5b9",
   "metadata": {},
   "source": [
    "### Configure a hyperparameter job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353bdec-e3e7-410a-a723-8c002f3c4f57",
   "metadata": {},
   "source": [
    "#### Set HugeCTR model and trainer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f20ce01-d020-4d8a-bdf0-0102bd9d5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODULE = 'trainer.task'\n",
    "\n",
    "NUM_EPOCHS = 0\n",
    "MAX_ITERATIONS = 10000\n",
    "EVAL_INTERVAL = 1000\n",
    "EVAL_BATCHES = 500\n",
    "EVAL_BATCHES_FINAL = 2500\n",
    "DISPLAY_INTERVAL = 200\n",
    "SNAPSHOT_INTERVAL = 0\n",
    "WORKSPACE_SIZE_PER_GPU = 61\n",
    "PER_GPU_BATCHSIZE = 2048\n",
    "NUM_WORKERS = 12\n",
    "SLOT_SIZE_ARRAY = json.dumps(\n",
    "    [int(cardinality) for cardinality in cardinalities.values()]).replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc77717-8200-40d4-a093-7a9204bcebd8",
   "metadata": {},
   "source": [
    "#### Set training node configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e813368a-4e56-4753-9a25-ea068565a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'a2-highgpu-4g'\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "ACCELERATOR_NUM = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac41445-6dc1-45e5-bc17-98667056af2f",
   "metadata": {},
   "source": [
    "#### Configure worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51db43af-3ed1-47ee-baca-e17677f7e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = PER_GPU_BATCHSIZE * ACCELERATOR_NUM\n",
    "gpus = json.dumps([list(range(ACCELERATOR_NUM))]).replace(' ','')\n",
    "                 \n",
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [\"python\", \"-m\", TRAINING_MODULE],\n",
    "            \"args\": [\n",
    "                '--batchsize=' + str(batchsize),\n",
    "                '--train_data=' + TRAIN_DATA.replace('gs://', '/gcs/'), \n",
    "                '--valid_data=' + VALID_DATA.replace('gs://', '/gcs/'),\n",
    "                '--slot_size_array=' + SLOT_SIZE_ARRAY,\n",
    "                '--max_iter=' + str(MAX_ITERATIONS),\n",
    "                '--max_eval_batches=' + str(EVAL_BATCHES),\n",
    "                '--eval_batches=' + str(EVAL_BATCHES_FINAL),\n",
    "                '--num_workers=' + str(NUM_WORKERS),\n",
    "                '--num_epochs=' + str(NUM_EPOCHS),\n",
    "                '--eval_interval=' + str(EVAL_INTERVAL),\n",
    "                '--snapshot=' + str(SNAPSHOT_INTERVAL),\n",
    "                '--display_interval=' + str(DISPLAY_INTERVAL),\n",
    "                '--workspace_size_per_gpu=' + str(WORKSPACE_SIZE_PER_GPU),\n",
    "                '--gpus=' + gpus,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507bcd7-7789-4630-b4c6-69d0c8aa9c93",
   "metadata": {},
   "source": [
    "#### Configure hyperparameter and metric specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0425cdf-07bc-4cf5-b3f7-858fdbc40fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_spec = {'AUC': 'maximize'}\n",
    "\n",
    "parameter_spec = {\n",
    "    'lr': hpt.DoubleParameterSpec(min=0.001, max=0.01, scale='log'),\n",
    "    'dropout_rate': hpt.DiscreteParameterSpec(values=[0.4, 0.5, 0.6], scale=None),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbadf45-f41b-4c99-a620-fd73062b072d",
   "metadata": {},
   "source": [
    "### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00435e4d-6833-4034-9bad-e2f46a1c75a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating HyperparameterTuningJob\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob created. Resource name: projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472\n",
      "INFO:google.cloud.aiplatform.jobs:To use this HyperparameterTuningJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:hpt_job = aiplatform.HyperparameterTuningJob.get('projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472')\n",
      "INFO:google.cloud.aiplatform.jobs:View HyperparameterTuningJob:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2160454586672873472?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob run completed. Resource name: projects/895222332033/locations/us-central1/hyperparameterTuningJobs/2160454586672873472\n"
     ]
    }
   ],
   "source": [
    "job_name = 'HUGECTR_HTUNING_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{VERTEX_STAGING_BUCKET}/job_dir/{job_name}'\n",
    "\n",
    "\n",
    "custom_job = aiplatform.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "\n",
    "hp_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=job_name,\n",
    "    custom_job=custom_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=4,\n",
    "    parallel_trial_count=2,\n",
    "    search_algorithm=None)\n",
    "\n",
    "hp_job.run(\n",
    "    sync=True,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832fbaa-f32e-4bac-b53b-5b0639cd28bc",
   "metadata": {},
   "source": [
    "### Retrieve trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbcda9bf-3c5e-48ee-a75c-8dc197f96c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"1\"\n",
       " state: SUCCEEDED\n",
       " parameters {\n",
       "   parameter_id: \"dropout_rate\"\n",
       "   value {\n",
       "     number_value: 0.5\n",
       "   }\n",
       " }\n",
       " parameters {\n",
       "   parameter_id: \"lr\"\n",
       "   value {\n",
       "     number_value: 0.0031622776601683794\n",
       "   }\n",
       " }\n",
       " final_measurement {\n",
       "   step_count: 10000\n",
       "   metrics {\n",
       "     metric_id: \"AUC\"\n",
       "     value: 0.6418014764785767\n",
       "   }\n",
       " }\n",
       " start_time {\n",
       "   seconds: 1634230319\n",
       "   nanos: 373439804\n",
       " }\n",
       " end_time {\n",
       "   seconds: 1634231353\n",
       " },\n",
       " id: \"2\"\n",
       " state: SUCCEEDED\n",
       " parameters {\n",
       "   parameter_id: \"dropout_rate\"\n",
       "   value {\n",
       "     number_value: 0.4\n",
       "   }\n",
       " }\n",
       " parameters {\n",
       "   parameter_id: \"lr\"\n",
       "   value {\n",
       "     number_value: 0.0019070834044189785\n",
       "   }\n",
       " }\n",
       " final_measurement {\n",
       "   step_count: 10000\n",
       "   metrics {\n",
       "     metric_id: \"AUC\"\n",
       "     value: 0.6543273329734802\n",
       "   }\n",
       " }\n",
       " start_time {\n",
       "   seconds: 1634230319\n",
       "   nanos: 373603250\n",
       " }\n",
       " end_time {\n",
       "   seconds: 1634231349\n",
       " },\n",
       " id: \"3\"\n",
       " state: SUCCEEDED\n",
       " parameters {\n",
       "   parameter_id: \"dropout_rate\"\n",
       "   value {\n",
       "     number_value: 0.5\n",
       "   }\n",
       " }\n",
       " parameters {\n",
       "   parameter_id: \"lr\"\n",
       "   value {\n",
       "     number_value: 0.001097452670601909\n",
       "   }\n",
       " }\n",
       " final_measurement {\n",
       "   step_count: 10000\n",
       "   metrics {\n",
       "     metric_id: \"AUC\"\n",
       "     value: 0.5971439480781555\n",
       "   }\n",
       " }\n",
       " start_time {\n",
       "   seconds: 1634231563\n",
       "   nanos: 936978002\n",
       " }\n",
       " end_time {\n",
       "   seconds: 1634232591\n",
       " },\n",
       " id: \"4\"\n",
       " state: SUCCEEDED\n",
       " parameters {\n",
       "   parameter_id: \"dropout_rate\"\n",
       "   value {\n",
       "     number_value: 0.4\n",
       "   }\n",
       " }\n",
       " parameters {\n",
       "   parameter_id: \"lr\"\n",
       "   value {\n",
       "     number_value: 0.00347031635066004\n",
       "   }\n",
       " }\n",
       " final_measurement {\n",
       "   step_count: 10000\n",
       "   metrics {\n",
       "     metric_id: \"AUC\"\n",
       "     value: 0.6567307710647583\n",
       "   }\n",
       " }\n",
       " start_time {\n",
       "   seconds: 1634231565\n",
       "   nanos: 462715026\n",
       " }\n",
       " end_time {\n",
       "   seconds: 1634232609\n",
       " }]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_job.trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f589c-4fc2-4a85-a56a-d099abb1853a",
   "metadata": {},
   "source": [
    "#### Find the best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1207b49b-e0e1-4711-9ef2-4db18cda8fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial ID: 4\n",
      "   AUC: 0.6567307710647583\n",
      "   LR: 0.00347031635066004\n",
      "   Dropout rate: 0.4\n"
     ]
    }
   ],
   "source": [
    "def retrieve_auc(trial):\n",
    "    auc = trial.final_measurement.metrics[0].value\n",
    "    \n",
    "    return auc\n",
    " \n",
    "best_trial = sorted(hp_job.trials, key=retrieve_auc, reverse=True)[0]\n",
    "\n",
    "print(\"Best trial ID:\", best_trial.id)\n",
    "print(\"   AUC:\", best_trial.final_measurement.metrics[0].value)\n",
    "print(\"   LR:\", best_trial.parameters[1].value)\n",
    "print(\"   Dropout rate:\", best_trial.parameters[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a992c6c-285b-4fc6-b8c2-1eb2d63beefb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m80"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
