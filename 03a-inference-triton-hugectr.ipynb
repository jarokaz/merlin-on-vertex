{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7086876-72ed-4ac8-aeba-f05dbc641798",
   "metadata": {},
   "source": [
    "# Using Vertex AI for online serving with NVIDIA Triton\n",
    "\n",
    "- Demonstrate serving of ensemble models - NVTabular preprocessing + HugeCTR recommender\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7701ef0-b9be-4b42-b2a9-2e96196297b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Couldn't build proto file into descriptor pool!\nInvalid proto descriptor for file \"model_config.proto\":\n  model_config.proto: A file with this name is already in the pool.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21854/943274016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnvtabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriton\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_hugectr_ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nvtabular/inference/triton/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtritonclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_to_triton_dtype\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnvtabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_config\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnvtabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_list_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_string_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_make_df\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnvtabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_embedding_sizes\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nvtabular/inference/triton/model_config_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mserialized_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mcreate_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_create_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mserialized_pb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mb'\\n\\x12model_config.proto\\x12\\tinference\\\"\\x96\\x01\\n\\x10ModelRateLimiter\\x12\\x37\\n\\tresources\\x18\\x01 \\x03(\\x0b\\x32$.inference.ModelRateLimiter.Resource\\x12\\x10\\n\\x08priority\\x18\\x02 \\x01(\\r\\x1a\\x37\\n\\x08Resource\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0e\\n\\x06global\\x18\\x02 \\x01(\\x08\\x12\\r\\n\\x05\\x63ount\\x18\\x03 \\x01(\\r\\\"\\xf8\\x01\\n\\x12ModelInstanceGroup\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x30\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\\".inference.ModelInstanceGroup.Kind\\x12\\r\\n\\x05\\x63ount\\x18\\x02 \\x01(\\x05\\x12\\x31\\n\\x0crate_limiter\\x18\\x06 \\x01(\\x0b\\x32\\x1b.inference.ModelRateLimiter\\x12\\x0c\\n\\x04gpus\\x18\\x03 \\x03(\\x05\\x12\\x0f\\n\\x07profile\\x18\\x05 \\x03(\\t\\\"A\\n\\x04Kind\\x12\\r\\n\\tKIND_AUTO\\x10\\x00\\x12\\x0c\\n\\x08KIND_GPU\\x10\\x01\\x12\\x0c\\n\\x08KIND_CPU\\x10\\x02\\x12\\x0e\\n\\nKIND_MODEL\\x10\\x03\\\"#\\n\\x12ModelTensorReshape\\x12\\r\\n\\x05shape\\x18\\x01 \\x03(\\x03\\\"\\xa0\\x02\\n\\nModelInput\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12&\\n\\tdata_type\\x18\\x02 \\x01(\\x0e\\x32\\x13.inference.DataType\\x12,\\n\\x06\\x66ormat\\x18\\x03 \\x01(\\x0e\\x32\\x1c.inference.ModelInput.Format\\x12\\x0c\\n\\x04\\x64ims\\x18\\x04 \\x03(\\x03\\x12.\\n\\x07reshape\\x18\\x05 \\x01(\\x0b\\x32\\x1d.inference.ModelTensorReshape\\x12\\x17\\n\\x0fis_shape_tensor\\x18\\x06 \\x01(\\x08\\x12\\x1a\\n\\x12\\x61llow_ragged_batch\\x18\\x07 \\x01(\\x08\\\";\\n\\x06\\x46ormat\\x12\\x0f\\n\\x0b\\x46ORMAT_NONE\\x10\\x00\\x12\\x0f\\n\\x0b\\x46ORMAT_NHWC\\x10\\x01\\x12\\x0f\\n\\x0b\\x46ORMAT_NCHW\\x10\\x02\\\"\\xb2\\x01\\n\\x0bModelOutput\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12&\\n\\tdata_type\\x18\\x02 \\x01(\\x0e\\x32\\x13.inference.DataType\\x12\\x0c\\n\\x04\\x64ims\\x18\\x03 \\x03(\\x03\\x12.\\n\\x07reshape\\x18\\x05 \\x01(\\x0b\\x32\\x1d.inference.ModelTensorReshape\\x12\\x16\\n\\x0elabel_filename\\x18\\x04 \\x01(\\t\\x12\\x17\\n\\x0fis_shape_tensor\\x18\\x06 \\x01(\\x08\\\"\\xa5\\x02\\n\\nBatchInput\\x12(\\n\\x04kind\\x18\\x01 \\x01(\\x0e\\x32\\x1a.inference.BatchInput.Kind\\x12\\x13\\n\\x0btarget_name\\x18\\x02 \\x03(\\t\\x12&\\n\\tdata_type\\x18\\x03 \\x01(\\x0e\\x32\\x13.inference.DataType\\x12\\x14\\n\\x0csource_input\\x18\\x04 \\x03(\\t\\\"\\x99\\x01\\n\\x04Kind\\x12\\x17\\n\\x13\\x42\\x41TCH_ELEMENT_COUNT\\x10\\x00\\x12#\\n\\x1f\\x42\\x41TCH_ACCUMULATED_ELEMENT_COUNT\\x10\\x01\\x12-\\n)BATCH_ACCUMULATED_ELEMENT_COUNT_WITH_ZERO\\x10\\x02\\x12$\\n BATCH_MAX_ELEMENT_COUNT_AS_SHAPE\\x10\\x03\\\"\\x8f\\x01\\n\\x0b\\x42\\x61tchOutput\\x12\\x13\\n\\x0btarget_name\\x18\\x01 \\x03(\\t\\x12)\\n\\x04kind\\x18\\x02 \\x01(\\x0e\\x32\\x1b.inference.BatchOutput.Kind\\x12\\x14\\n\\x0csource_input\\x18\\x03 \\x03(\\t\\\"*\\n\\x04Kind\\x12\\\"\\n\\x1e\\x42\\x41TCH_SCATTER_WITH_INPUT_SHAPE\\x10\\x00\\\"\\x90\\x02\\n\\x12ModelVersionPolicy\\x12\\x36\\n\\x06latest\\x18\\x01 \\x01(\\x0b\\x32$.inference.ModelVersionPolicy.LatestH\\x00\\x12\\x30\\n\\x03\\x61ll\\x18\\x02 \\x01(\\x0b\\x32!.inference.ModelVersionPolicy.AllH\\x00\\x12:\\n\\x08specific\\x18\\x03 \\x01(\\x0b\\x32&.inference.ModelVersionPolicy.SpecificH\\x00\\x1a\\x1e\\n\\x06Latest\\x12\\x14\\n\\x0cnum_versions\\x18\\x01 \\x01(\\r\\x1a\\x05\\n\\x03\\x41ll\\x1a\\x1c\\n\\x08Specific\\x12\\x10\\n\\x08versions\\x18\\x01 \\x03(\\x03\\x42\\x0f\\n\\rpolicy_choice\\\"\\xa1\\r\\n\\x17ModelOptimizationPolicy\\x12\\x37\\n\\x05graph\\x18\\x01 \\x01(\\x0b\\x32(.inference.ModelOptimizationPolicy.Graph\\x12\\x42\\n\\x08priority\\x18\\x02 \\x01(\\x0e\\x32\\x30.inference.ModelOptimizationPolicy.ModelPriority\\x12\\x35\\n\\x04\\x63uda\\x18\\x03 \\x01(\\x0b\\x32\\'.inference.ModelOptimizationPolicy.Cuda\\x12X\\n\\x16\\x65xecution_accelerators\\x18\\x04 \\x01(\\x0b\\x32\\x38.inference.ModelOptimizationPolicy.ExecutionAccelerators\\x12R\\n\\x13input_pinned_memory\\x18\\x05 \\x01(\\x0b\\x32\\x35.inference.ModelOptimizationPolicy.PinnedMemoryBuffer\\x12S\\n\\x14output_pinned_memory\\x18\\x06 \\x01(\\x0b\\x32\\x35.inference.ModelOptimizationPolicy.PinnedMemoryBuffer\\x1a\\x16\\n\\x05Graph\\x12\\r\\n\\x05level\\x18\\x01 \\x01(\\x05\\x1a\\x9e\\x05\\n\\x04\\x43uda\\x12\\x0e\\n\\x06graphs\\x18\\x01 \\x01(\\x08\\x12\\x18\\n\\x10\\x62usy_wait_events\\x18\\x02 \\x01(\\x08\\x12\\x45\\n\\ngraph_spec\\x18\\x03 \\x03(\\x0b\\x32\\x31.inference.ModelOptimizationPolicy.Cuda.GraphSpec\\x1a\\xa4\\x04\\n\\tGraphSpec\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\x05\\x12K\\n\\x05input\\x18\\x02 \\x03(\\x0b\\x32<.inference.ModelOptimizationPolicy.Cuda.GraphSpec.InputEntry\\x12W\\n\\x11graph_lower_bound\\x18\\x03 \\x01(\\x0b\\x32<.inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound\\x1a\\x14\\n\\x05Shape\\x12\\x0b\\n\\x03\\x64im\\x18\\x01 \\x03(\\x03\\x1a\\xdf\\x01\\n\\nLowerBound\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\x05\\x12V\\n\\x05input\\x18\\x02 \\x03(\\x0b\\x32G.inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.InputEntry\\x1a\\x65\\n\\nInputEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\x46\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x37.inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape:\\x02\\x38\\x01\\x1a\\x65\\n\\nInputEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\x46\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x37.inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape:\\x02\\x38\\x01\\x1a\\xa4\\x03\\n\\x15\\x45xecutionAccelerators\\x12g\\n\\x19gpu_execution_accelerator\\x18\\x01 \\x03(\\x0b\\x32\\x44.inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator\\x12g\\n\\x19\\x63pu_execution_accelerator\\x18\\x02 \\x03(\\x0b\\x32\\x44.inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator\\x1a\\xb8\\x01\\n\\x0b\\x41\\x63\\x63\\x65lerator\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12h\\n\\nparameters\\x18\\x02 \\x03(\\x0b\\x32T.inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.ParametersEntry\\x1a\\x31\\n\\x0fParametersEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05value\\x18\\x02 \\x01(\\t:\\x02\\x38\\x01\\x1a$\\n\\x12PinnedMemoryBuffer\\x12\\x0e\\n\\x06\\x65nable\\x18\\x01 \\x01(\\x08\\\"I\\n\\rModelPriority\\x12\\x14\\n\\x10PRIORITY_DEFAULT\\x10\\x00\\x12\\x10\\n\\x0cPRIORITY_MAX\\x10\\x01\\x12\\x10\\n\\x0cPRIORITY_MIN\\x10\\x02\\\"\\xdb\\x01\\n\\x10ModelQueuePolicy\\x12\\x41\\n\\x0etimeout_action\\x18\\x01 \\x01(\\x0e\\x32).inference.ModelQueuePolicy.TimeoutAction\\x12$\\n\\x1c\\x64\\x65\\x66\\x61ult_timeout_microseconds\\x18\\x02 \\x01(\\x04\\x12\\x1e\\n\\x16\\x61llow_timeout_override\\x18\\x03 \\x01(\\x08\\x12\\x16\\n\\x0emax_queue_size\\x18\\x04 \\x01(\\r\\\"&\\n\\rTimeoutAction\\x12\\n\\n\\x06REJECT\\x10\\x00\\x12\\t\\n\\x05\\x44\\x45LAY\\x10\\x01\\\"\\x9b\\x03\\n\\x14ModelDynamicBatching\\x12\\x1c\\n\\x14preferred_batch_size\\x18\\x01 \\x03(\\x05\\x12$\\n\\x1cmax_queue_delay_microseconds\\x18\\x02 \\x01(\\x04\\x12\\x19\\n\\x11preserve_ordering\\x18\\x03 \\x01(\\x08\\x12\\x17\\n\\x0fpriority_levels\\x18\\x04 \\x01(\\r\\x12\\x1e\\n\\x16\\x64\\x65\\x66\\x61ult_priority_level\\x18\\x05 \\x01(\\r\\x12\\x39\\n\\x14\\x64\\x65\\x66\\x61ult_queue_policy\\x18\\x06 \\x01(\\x0b\\x32\\x1b.inference.ModelQueuePolicy\\x12W\\n\\x15priority_queue_policy\\x18\\x07 \\x03(\\x0b\\x32\\x38.inference.ModelDynamicBatching.PriorityQueuePolicyEntry\\x1aW\\n\\x18PriorityQueuePolicyEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\r\\x12*\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x1b.inference.ModelQueuePolicy:\\x02\\x38\\x01\\\"\\xe3\\x06\\n\\x15ModelSequenceBatching\\x12\\x41\\n\\x06\\x64irect\\x18\\x03 \\x01(\\x0b\\x32/.inference.ModelSequenceBatching.StrategyDirectH\\x00\\x12\\x41\\n\\x06oldest\\x18\\x04 \\x01(\\x0b\\x32/.inference.ModelSequenceBatching.StrategyOldestH\\x00\\x12&\\n\\x1emax_sequence_idle_microseconds\\x18\\x01 \\x01(\\x04\\x12\\x44\\n\\rcontrol_input\\x18\\x02 \\x03(\\x0b\\x32-.inference.ModelSequenceBatching.ControlInput\\x1a\\x98\\x02\\n\\x07\\x43ontrol\\x12;\\n\\x04kind\\x18\\x01 \\x01(\\x0e\\x32-.inference.ModelSequenceBatching.Control.Kind\\x12\\x18\\n\\x10int32_false_true\\x18\\x02 \\x03(\\x05\\x12\\x17\\n\\x0f\\x66p32_false_true\\x18\\x03 \\x03(\\x02\\x12&\\n\\tdata_type\\x18\\x04 \\x01(\\x0e\\x32\\x13.inference.DataType\\\"u\\n\\x04Kind\\x12\\x1a\\n\\x16\\x43ONTROL_SEQUENCE_START\\x10\\x00\\x12\\x1a\\n\\x16\\x43ONTROL_SEQUENCE_READY\\x10\\x01\\x12\\x18\\n\\x14\\x43ONTROL_SEQUENCE_END\\x10\\x02\\x12\\x1b\\n\\x17\\x43ONTROL_SEQUENCE_CORRID\\x10\\x03\\x1aW\\n\\x0c\\x43ontrolInput\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x39\\n\\x07\\x63ontrol\\x18\\x02 \\x03(\\x0b\\x32(.inference.ModelSequenceBatching.Control\\x1aX\\n\\x0eStrategyDirect\\x12$\\n\\x1cmax_queue_delay_microseconds\\x18\\x01 \\x01(\\x04\\x12 \\n\\x18minimum_slot_utilization\\x18\\x02 \\x01(\\x02\\x1au\\n\\x0eStrategyOldest\\x12\\x1f\\n\\x17max_candidate_sequences\\x18\\x01 \\x01(\\x05\\x12\\x1c\\n\\x14preferred_batch_size\\x18\\x02 \\x03(\\x05\\x12$\\n\\x1cmax_queue_delay_microseconds\\x18\\x03 \\x01(\\x04\\x42\\x11\\n\\x0fstrategy_choice\\\"\\xdd\\x02\\n\\x0fModelEnsembling\\x12-\\n\\x04step\\x18\\x01 \\x03(\\x0b\\x32\\x1f.inference.ModelEnsembling.Step\\x1a\\x9a\\x02\\n\\x04Step\\x12\\x12\\n\\nmodel_name\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rmodel_version\\x18\\x02 \\x01(\\x03\\x12@\\n\\tinput_map\\x18\\x03 \\x03(\\x0b\\x32-.inference.ModelEnsembling.Step.InputMapEntry\\x12\\x42\\n\\noutput_map\\x18\\x04 \\x03(\\x0b\\x32..inference.ModelEnsembling.Step.OutputMapEntry\\x1a/\\n\\rInputMapEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05value\\x18\\x02 \\x01(\\t:\\x02\\x38\\x01\\x1a\\x30\\n\\x0eOutputMapEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05value\\x18\\x02 \\x01(\\t:\\x02\\x38\\x01\\\"&\\n\\x0eModelParameter\\x12\\x14\\n\\x0cstring_value\\x18\\x01 \\x01(\\t\\\"\\xca\\x02\\n\\x0bModelWarmup\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x02 \\x01(\\r\\x12\\x32\\n\\x06inputs\\x18\\x03 \\x03(\\x0b\\x32\\\".inference.ModelWarmup.InputsEntry\\x1a\\x97\\x01\\n\\x05Input\\x12&\\n\\tdata_type\\x18\\x01 \\x01(\\x0e\\x32\\x13.inference.DataType\\x12\\x0c\\n\\x04\\x64ims\\x18\\x02 \\x03(\\x03\\x12\\x13\\n\\tzero_data\\x18\\x03 \\x01(\\x08H\\x00\\x12\\x15\\n\\x0brandom_data\\x18\\x04 \\x01(\\x08H\\x00\\x12\\x19\\n\\x0finput_data_file\\x18\\x05 \\x01(\\tH\\x00\\x42\\x11\\n\\x0finput_data_type\\x1aK\\n\\x0bInputsEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12+\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x1c.inference.ModelWarmup.Input:\\x02\\x38\\x01\\\".\\n\\x0fModelOperations\\x12\\x1b\\n\\x13op_library_filename\\x18\\x01 \\x03(\\t\\\"+\\n\\x16ModelTransactionPolicy\\x12\\x11\\n\\tdecoupled\\x18\\x01 \\x01(\\x08\\\"\\xb8\\t\\n\\x0bModelConfig\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x08platform\\x18\\x02 \\x01(\\t\\x12\\x0f\\n\\x07\\x62\\x61\\x63kend\\x18\\x11 \\x01(\\t\\x12\\x35\\n\\x0eversion_policy\\x18\\x03 \\x01(\\x0b\\x32\\x1d.inference.ModelVersionPolicy\\x12\\x16\\n\\x0emax_batch_size\\x18\\x04 \\x01(\\x05\\x12$\\n\\x05input\\x18\\x05 \\x03(\\x0b\\x32\\x15.inference.ModelInput\\x12&\\n\\x06output\\x18\\x06 \\x03(\\x0b\\x32\\x16.inference.ModelOutput\\x12*\\n\\x0b\\x62\\x61tch_input\\x18\\x14 \\x03(\\x0b\\x32\\x15.inference.BatchInput\\x12,\\n\\x0c\\x62\\x61tch_output\\x18\\x15 \\x03(\\x0b\\x32\\x16.inference.BatchOutput\\x12\\x38\\n\\x0coptimization\\x18\\x0c \\x01(\\x0b\\x32\\\".inference.ModelOptimizationPolicy\\x12;\\n\\x10\\x64ynamic_batching\\x18\\x0b \\x01(\\x0b\\x32\\x1f.inference.ModelDynamicBatchingH\\x00\\x12=\\n\\x11sequence_batching\\x18\\r \\x01(\\x0b\\x32 .inference.ModelSequenceBatchingH\\x00\\x12\\x39\\n\\x13\\x65nsemble_scheduling\\x18\\x0f \\x01(\\x0b\\x32\\x1a.inference.ModelEnsemblingH\\x00\\x12\\x35\\n\\x0einstance_group\\x18\\x07 \\x03(\\x0b\\x32\\x1d.inference.ModelInstanceGroup\\x12\\x1e\\n\\x16\\x64\\x65\\x66\\x61ult_model_filename\\x18\\x08 \\x01(\\t\\x12H\\n\\x12\\x63\\x63_model_filenames\\x18\\t \\x03(\\x0b\\x32,.inference.ModelConfig.CcModelFilenamesEntry\\x12;\\n\\x0bmetric_tags\\x18\\n \\x03(\\x0b\\x32&.inference.ModelConfig.MetricTagsEntry\\x12:\\n\\nparameters\\x18\\x0e \\x03(\\x0b\\x32&.inference.ModelConfig.ParametersEntry\\x12,\\n\\x0cmodel_warmup\\x18\\x10 \\x03(\\x0b\\x32\\x16.inference.ModelWarmup\\x12\\x34\\n\\x10model_operations\\x18\\x12 \\x01(\\x0b\\x32\\x1a.inference.ModelOperations\\x12\\x43\\n\\x18model_transaction_policy\\x18\\x13 \\x01(\\x0b\\x32!.inference.ModelTransactionPolicy\\x1a\\x37\\n\\x15\\x43\\x63ModelFilenamesEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05value\\x18\\x02 \\x01(\\t:\\x02\\x38\\x01\\x1a\\x31\\n\\x0fMetricTagsEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05value\\x18\\x02 \\x01(\\t:\\x02\\x38\\x01\\x1aL\\n\\x0fParametersEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12(\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x19.inference.ModelParameter:\\x02\\x38\\x01\\x42\\x13\\n\\x11scheduling_choice*\\xeb\\x01\\n\\x08\\x44\\x61taType\\x12\\x10\\n\\x0cTYPE_INVALID\\x10\\x00\\x12\\r\\n\\tTYPE_BOOL\\x10\\x01\\x12\\x0e\\n\\nTYPE_UINT8\\x10\\x02\\x12\\x0f\\n\\x0bTYPE_UINT16\\x10\\x03\\x12\\x0f\\n\\x0bTYPE_UINT32\\x10\\x04\\x12\\x0f\\n\\x0bTYPE_UINT64\\x10\\x05\\x12\\r\\n\\tTYPE_INT8\\x10\\x06\\x12\\x0e\\n\\nTYPE_INT16\\x10\\x07\\x12\\x0e\\n\\nTYPE_INT32\\x10\\x08\\x12\\x0e\\n\\nTYPE_INT64\\x10\\t\\x12\\r\\n\\tTYPE_FP16\\x10\\n\\x12\\r\\n\\tTYPE_FP32\\x10\\x0b\\x12\\r\\n\\tTYPE_FP64\\x10\\x0c\\x12\\x0f\\n\\x0bTYPE_STRING\\x10\\rb\\x06proto3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, package, options, serialized_options, serialized_pb, dependencies, public_dependencies, syntax, pool, create_key)\u001b[0m\n\u001b[1;32m    980\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please link in cpp generated lib for %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mserialized_pb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddSerializedFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_pb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileDescriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Couldn't build proto file into descriptor pool!\nInvalid proto descriptor for file \"model_config.proto\":\n  model_config.proto: A file with this name is already in the pool.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from nvtabular.inference.triton import export_hugectr_ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74096b-72b1-46f2-8478-6a6d41743af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m80"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
