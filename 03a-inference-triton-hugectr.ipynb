{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7086876-72ed-4ac8-aeba-f05dbc641798",
   "metadata": {},
   "source": [
    "# Using Vertex AI for online serving with NVIDIA Triton\n",
    "\n",
    "- Demonstrate serving of ensemble models - NVTabular preprocessing + HugeCTR recommender\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7701ef0-b9be-4b42-b2a9-2e96196297b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d084e2-740d-4ba3-b783-73d1116da103",
   "metadata": {},
   "source": [
    "### Configure notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de09acc2-b57b-4799-ba47-2e1c4ba99aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"gs://jk-merlin-dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4db25-32cd-4a64-a366-6950d11b7e1f",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b6cce1-b15f-440e-a098-84094b416cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcf6c8-84b6-413b-8796-fc8d6791edfc",
   "metadata": {},
   "source": [
    "### Build a custom prediction container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b022fdb-a828-4dc6-a12a-b1d896ab1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = 'triton-hugectr'\n",
    "IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{IMAGE_NAME}\"\n",
    "DOCKERFILE = 'src/Dockerfile.triton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc86828-e956-4d03-956d-7fe52da63121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  443.4kB\n",
      "Step 1/9 : FROM gcr.io/merlin-on-gcp/dongm-merlin-inference-hugectr:v0.6.1\n",
      " ---> fb6f7db2d7fd\n",
      "Step 2/9 : EXPOSE 8000\n",
      " ---> Using cache\n",
      " ---> 748ffab38b92\n",
      "Step 3/9 : EXPOSE 8001\n",
      " ---> Using cache\n",
      " ---> b2636665a789\n",
      "Step 4/9 : EXPOSE 8002\n",
      " ---> Using cache\n",
      " ---> ab2a74e7be2d\n",
      "Step 5/9 : RUN echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg  add - && apt-get update -y && apt-get install google-cloud-sdk -y\n",
      " ---> Using cache\n",
      " ---> 13367d28a72a\n",
      "Step 6/9 : WORKDIR /src\n",
      " ---> Using cache\n",
      " ---> 6cbfc3ce26b4\n",
      "Step 7/9 : COPY inference/entrypoint.sh ./\n",
      " ---> Using cache\n",
      " ---> 662ab5a494af\n",
      "Step 8/9 : RUN chmod +x entrypoint.sh\n",
      " ---> Using cache\n",
      " ---> a6a1045b69a5\n",
      "Step 9/9 : ENTRYPOINT [\"./entrypoint.sh\"]\n",
      " ---> Using cache\n",
      " ---> 8f63188b0281\n",
      "Successfully built 8f63188b0281\n",
      "Successfully tagged gcr.io/jk-mlops-dev/triton-hugectr:latest\n",
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/triton-hugectr]\n",
      "\n",
      "\u001b[1Be8c21ae4: Preparing \n",
      "\u001b[1Bcc04aff3: Preparing \n",
      "\u001b[1Bde7de102: Preparing \n",
      "\u001b[1Be58e8598: Preparing \n",
      "\u001b[1Bc9824aed: Preparing \n",
      "\u001b[1B23fe2ec9: Preparing \n",
      "\u001b[1Beb0eea4e: Preparing \n",
      "\u001b[1B08de1536: Preparing \n",
      "\u001b[1Bd698577a: Preparing \n",
      "\u001b[1B21cc7b5f: Preparing \n",
      "\u001b[1B646f53eb: Preparing \n",
      "\u001b[1Bf0fe3ed8: Preparing \n",
      "\u001b[1B7d455483: Preparing \n",
      "\u001b[1B026e0fab: Preparing \n",
      "\u001b[1B9b492bd7: Preparing \n",
      "\u001b[1B2784440c: Preparing \n",
      "\u001b[1B2f6421c3: Preparing \n",
      "\u001b[1B8a55152d: Preparing \n",
      "\u001b[1B589ca15a: Preparing \n",
      "\u001b[1B0a50ea64: Preparing \n",
      "\u001b[1B64c9831d: Preparing \n",
      "\u001b[1B42df9148: Preparing \n",
      "\u001b[1B4e7260d1: Preparing \n",
      "\u001b[19B3fe2ec9: Waiting g \n",
      "\u001b[19Bb0eea4e: Waiting g \n",
      "\u001b[1B5d96cc97: Preparing \n",
      "\u001b[1B41d8a723: Preparing \n",
      "\u001b[19B1cc7b5f: Waiting g \n",
      "\u001b[22B8de1536: Waiting g \n",
      "\u001b[1B357bd24c: Preparing \n",
      "\u001b[1Bb05908c8: Preparing \n",
      "\u001b[1B4217793b: Preparing \n",
      "\u001b[22B0fe3ed8: Waiting g \n",
      "\u001b[1B7c006461: Preparing \n",
      "\u001b[27B698577a: Waiting g \n",
      "\u001b[12Ba137864: Waiting g \n",
      "\u001b[24B26e0fab: Waiting g \n",
      "\u001b[13Bd96cc97: Waiting g \n",
      "\u001b[9Bb05908c8: Waiting g \n",
      "\u001b[26Bb492bd7: Waiting g \n",
      "\u001b[1B6c27cf6e: Preparing \n",
      "\u001b[1B9ecbfbfe: Preparing \n",
      "\u001b[28B784440c: Waiting g \n",
      "\u001b[26B89ca15a: Waiting g \n",
      "\u001b[1Bf46ba1c7: Preparing \n",
      "\u001b[15B217793b: Waiting g \n",
      "\u001b[28Ba50ea64: Waiting g \n",
      "\u001b[15Bc006461: Waiting g \n",
      "\u001b[29B4c9831d: Waiting g \n",
      "\u001b[13B8abd40a: Waiting g \n",
      "\u001b[15B8382770: Waiting g \n",
      "\u001b[1B4d6d50a7: Preparing \n",
      "\u001b[4Bc3489c5c: Waiting g \n",
      "\u001b[1B9a293c2f: Preparing \n",
      "\u001b[1B60a9947e: Preparing \n",
      "\u001b[5B4d6d50a7: Waiting g \n",
      "\u001b[1B2cb0a2aa: Preparing \n",
      "\u001b[1B13f0a43e: Preparing \n",
      "\u001b[7B2b1df38f: Waiting g \n",
      "\u001b[1B6d5c90ce: Preparing \n",
      "\u001b[5B2cb0a2aa: Waiting g \n",
      "\u001b[1B7c57c2d4: Preparing \n",
      "\u001b[5B98d0b77d: Waiting g \n",
      "\u001b[1B075e907e: Preparing \n",
      "\u001b[1Ba057adac: Preparing \n",
      "\u001b[1Ba85aee62: Preparing \n",
      "\u001b[6B7c57c2d4: Waiting g \n",
      "\u001b[4Ba057adac: Waiting g \n",
      "\u001b[4Ba85aee62: Waiting g \n",
      "\u001b[7B075e907e: Waiting g \n",
      "\u001b[3B316f3ae7: Waiting g \n",
      "\u001b[1B96ef8c35: Preparing \n",
      "\u001b[6B762bfd28: Waiting g \n",
      "\u001b[1B2cd6b836: Preparing \n",
      "\u001b[1B1da8e28f: Preparing \n",
      "\u001b[1Be435138d: Preparing \n",
      "\u001b[6B96ef8c35: Waiting g \n",
      "\u001b[76Be7de102: Pushed   611.7MB/586.2MB\u001b[72A\u001b[2K\u001b[76A\u001b[2K\u001b[71A\u001b[2K\u001b[69A\u001b[2K\u001b[67A\u001b[2K\u001b[65A\u001b[2K\u001b[63A\u001b[2K\u001b[61A\u001b[2K\u001b[59A\u001b[2K\u001b[57A\u001b[2K\u001b[76A\u001b[2K\u001b[54A\u001b[2K\u001b[76A\u001b[2K\u001b[50A\u001b[2K\u001b[48A\u001b[2K\u001b[46A\u001b[2K\u001b[76A\u001b[2K\u001b[43A\u001b[2K\u001b[40A\u001b[2K\u001b[78A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[27A\u001b[2K\u001b[23A\u001b[2K\u001b[19A\u001b[2K\u001b[14A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2K\u001b[76A\u001b[2Klatest: digest: sha256:2694b0ce65684aacc43c3f39d859b974464a6d12b98b908e8b8199000b82e3d5 size: 16916\n"
     ]
    }
   ],
   "source": [
    "!docker build -t {IMAGE_URI} -f {DOCKERFILE} src\n",
    "!docker push {IMAGE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582c27f-a3c0-4def-ac26-41d4007198bb",
   "metadata": {},
   "source": [
    "### Register the model resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f549c1-7466-43ae-8193-a395e313b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 11\n",
    "model_display_name = f\"{IMAGE_NAME}-deepfm-v{VERSION}\"\n",
    "model_description = \"Serving with Triton inference server using a custom container\"\n",
    "\n",
    "health_route = \"/v2/health/ready\"\n",
    "predict_route = f\"/v2/models/deepfm_ens/infer\"\n",
    "serving_container_ports = [8000]\n",
    "in_container_model_repository = '/models' # this should match the paths in ps.json and config.pbtxt in the ensemble\n",
    "serving_container_args = [in_container_model_repository]\n",
    "\n",
    "model_ensemble_location = 'gs://jk-criteo-bucket/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405d9fee-ab8e-4f96-b8f4-a66a47bea81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/895222332033/locations/us-central1/models/8773579422117658624/operations/9053342046907006976\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/895222332033/locations/us-central1/models/8773579422117658624\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/895222332033/locations/us-central1/models/8773579422117658624')\n",
      "triton-hugectr-deepfm-v11\n",
      "projects/895222332033/locations/us-central1/models/8773579422117658624\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    "    artifact_uri=model_ensemble_location,\n",
    "    serving_container_args=serving_container_args,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e652696-c49b-48d7-84ce-18d0e9d95fc6",
   "metadata": {},
   "source": [
    "### Create an endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e226a5-2f92-43c4-bc16-dd3bf1c3774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/895222332033/locations/us-central1/endpoints/3021361196105203712/operations/3899535223334895616\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/895222332033/locations/us-central1/endpoints/3021361196105203712\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/895222332033/locations/us-central1/endpoints/3021361196105203712')\n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{IMAGE_NAME}-endpoint-{VERSION}\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c264b-0d9d-4ed1-9f36-3fddb67fa9f4",
   "metadata": {},
   "source": [
    "### Deploy a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0906bfe-7e74-44f0-88d5-0ff6dbb8bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-16\"\n",
    "accelerator_type=\"NVIDIA_TESLA_T4\"\n",
    "accelerator_count = 1\n",
    "\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 1\n",
    "sync = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8fd54d-7478-424a-891f-01c732f6ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/895222332033/locations/us-central1/endpoints/3021361196105203712\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/895222332033/locations/us-central1/endpoints/3021361196105203712/operations/2440368944066854912\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/895222332033/locations/us-central1/endpoints/3021361196105203712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7fc709ec15d0> \n",
       "resource name: projects/895222332033/locations/us-central1/endpoints/3021361196105203712"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    min_replica_count=min_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    sync=sync,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2a392-ca07-47da-9944-fdc45163ec4a",
   "metadata": {},
   "source": [
    "### Test the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1765111a-6018-4554-bdc9-603def6bc10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"1\",\"model_name\":\"deepfm_ens\",\"model_version\":\"1\",\"parameters\":{\"sequence_id\":0,\"sequence_start\":false,\"sequence_end\":false},\"outputs\":[{\"name\":\"OUTPUT0\",\"datatype\":\"FP32\",\"shape\":[3],\"data\":[0.060752078890800479,0.0858408659696579,0.11432674527168274]}]}"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\"  \\\n",
    "  https://us-central1-aiplatform.googleapis.com/v1/projects/jk-mlops-dev/locations/us-central1/endpoints/3021361196105203712:rawPredict \\\n",
    "  -d @criteo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca8469-8a8f-43a2-b4c2-82dec329ea13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m80"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
